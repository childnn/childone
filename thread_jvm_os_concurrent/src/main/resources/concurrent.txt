Monitor 管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。
翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。
在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。
其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型。
在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；
另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。

-Xss: 允许的最小线程栈大小
-Xmx: JVM 的最大内存分配

并行: 多个程序互不影响, 同时执行 (同一时刻)  -- 多个人同时做多件事
并发: 多个程序在一段时间内,交替执行 -- 一个人 "同时" 做多件事

process: 进程.
thread: 线程, 轻量级进程(lightweight process).
现代操作系统把线程作为时序调度的基本单位.

write-once, run-anywhere.

deadlock 死锁
starvation 饥饿
livelock 活锁


线程的风险:
safe 安全危险.
    两个线程操作共享变量. -- 竞争条件(race condition).
    解决之一: synchronized 同步方法.
liveness failure 活跃度失败.
    一个活动进入某种它永远无法再继续执行的状态时, 活跃度失败就发生了.
     eg: 死循环中循环之后的代码; 多线程中, 线程 A 等待一个线程 B 独占的资源, B 永远不释放这个资源, A 将永远等待下去.
performance 性能.
     上下文切换: context switches.

共享: 一个变量可以被多个线程访问.
可变: 变量的值在其生命周期内可以改变.

在没有正确同步的情况下, 如果多个线程访问了同一个变量, 你的程序就存在隐患.
有 3 种方法修复它:
  1. 不要跨线程共享变量;
  2. 使状态变量为不可变的;
  3. 在任何访问状态变量的时候使用同步.

线程安全: 当多个线程访问一个类时, 如果不用考虑这些线程在运行时环境下的调度和交替执行, 并且不需要额外的
    同步及在调度方代码不必做其他的协调, 这个类的行为仍然是正确的, 那么称这个类是 线程安全的.

servlet 无状态性: 不包含域也没有引用其他类的域. 一个特定计算的瞬时状态, 会唯一地存在本地变量中, 这些本地变量存储
    在线程的栈中, 只有执行线程才能访问.
无状态对象永远是线程安全的.


volatile 的应用：
    1. 禁止指令的重排序优化(保证有序性);
    2. 提供内存可见性: 对一个 volatile 变量的读, 总能看到(任意线程)对这个 volatile 变量最后的写入;
    3. 不保证原子性: 对任意单个 volatile 变量的 读/写 具有原子性, 但类似 volatile++ 这种复合操作不具有原子性.
 在多线程并发编程中 synchronized 和 volatile 都扮演者重要角色， volatile 是轻量级的 synchronized，
 它在多处理器开发中保证了 共享变量的 “可见性”。 可见性的意思是当一个线程修改一个共享变量时，另外一个线程
 能读到这个修改的值。如果 volatile 变量修饰符使用恰当的话，它比 synchronized 的使用和执行成本更低，因为
 它不会引起线程上下文的切换和调度。
java 语言规范第三版中对 volatile 的定义如下：java 编程语言允许线程访问共享变量，为了确保共享变量能被准确和
一致地更新，线程应该确保通过排他锁单独获得这个变量。java 语言提供了 volatile，在某些情况下比锁要更加方便。
如果一个字段被声明成 volatile，java 线程内存模型确保所有线程看到这个变量的值是一致的。

volatile 与 synchronized
    1. volatile 关键字的作用就是强制从公共堆栈中取得变量的值, 而不是线程私有的数据栈中取得变量的值.
    2. volatile 是线程同步的轻量级实现, 性能比 synchronized 要好, 并且 volatile 只能修饰变量, 而 synchronized 可以
        修饰方法、代码块等.
    3. 多线程访问 volatile 不会发生阻塞, 而 synchronized 会发生阻塞.
    4. 可以保证数据的可见性, 但不可以抱枕原子性, 而 synchronized 可以保证原子性, 也可以间接保证可见性, 因为它会将
        私有内存和公共内存中共的数据做同步.
    5. volatile 解决的是变量在多个线程之间的可见性, 而 synchronized 解决的是多个线程之间访问资源的同步性.


相关的 CPU 术语
内存屏障         -- memory barriers           -- 一组处理器指令，用于实现对内存操作的顺序限制。
缓冲行           -- cache line                -- 缓存中可以分配的最小存储单位。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期。
原子操作         -- atomic operations         -- 不可中断的一个或一些列操作。
缓存行填充       -- cache line fill           -- 当处理器识别到从内存中读取操作是可缓存的，处理器读取整个缓存行到适当的缓存(L1, L2, L3 的或所有)。
缓存命中         -- cache hit                 -- 如果进行高速缓存填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取。
写命中           -- write hit                 -- 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中。如果存在一个有效的缓存行，
                                                 则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为 写命中。
写缺失           -- write misses the cache    -- 一个有效的缓存行被写入到不存在的内存区域。

volatile 的实现原则：
 1. Lock 前缀指令会引起处理器缓存回写到内存。 Lock 前缀指令导致在执行指令期间，声言处理器的 LOCK# 信号。
    在多处理器环境中，LOCK# 信号确保在声言该信号期间，处理器可以独占任何共享内存。但是，在最近的处理器里，LOCK# 信号
    一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。。。。使用 “缓存一致性机制来确保修改的原子性”，此操作被称为 “缓存锁定”，
    缓存一致性 机制会阻止同时修改两个以上处理器缓存的内存区域数据。
 2. 一个处理器的缓存会写到内存会导致其他处理器的缓存无效。
    IA-32 处理器和 Intel 64 处理器使用 MESI(修改,独占,共享,无效)控制协议去维护内部缓存和其他处理器缓存的一致性。
    在多核处理器系统中进行操作的时候，IA-32 和 Intel 64 处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用
    嗅探技术 保证它的内部缓存，系统内存和其他处理器的缓存数据在 总线上保持一致。例如，在 Pentium 和 P6 family 处理器中，如果通过
    嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同
    内存地址时，强制执行缓存行填充。

synchronized 会锁住总线，导致其他 CPU 不能访问总线，不能访问总线就意味着不能访问系统内存。
   “重量级锁”。java SE 1.6 对 synchronized 进行优化：为了减少 获得锁 和 释放锁 带来的性能消耗而引入的 偏向锁 和 轻量级锁，
   以及 锁的存储结构和升级过程。
基础：
 java 中的任一对象都可以作为 锁。具体表现在：
 1. 对于普通同步方法，锁是当前实例对象；
 2. 对于静态同步方法，锁是当前类的 Class 对象；
 3. 对于同步方法块，锁是 synchronized 括号里配置的对象。
 当一个线程视图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。
 那么 锁 到底在哪里呢？锁里面会存储什么信息呢？
    从 JVM 规范中可以看到 synchronized 在 JVM 里的实现原里，JVM 基于进入和退出 Monitor 对象来实现 方法 同步和 代码块 同步，但两者的实现细节不一样。
    代码块同步 是使用 monitorenter 和 monitorexit 指令实现的，而同步方法是使用另外一种方式实现的，细节在 JVM 规范并没有详细说明。但是，方法的同步
    同样可以使用这两个指令来实现。
   monitorenter 指令是在编译后插入到 同步代码块 的开始位置， 而 monitorexit 指令插入到方法的结束外和异常外，JVM 要保证每个 monitorenter 必须有对应的
   monitorexit 与之配对。任何对象都有一个 monitor 与之关联，当一个 monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令后，将会尝试获取
   对象所对应的 monitor 的所有权，即尝试获得对象的锁。
java 对象头
    synchronized 用的锁是存在 java 对象头里的。如果对象是数组类型，则虚拟机用 3 个字(word)宽存储对象头, 如果对象是非数组类型, 则用 2 字宽存储对象头.
    在 32 位虚拟机中, 1 字宽等于 4 个字节, 即 32 bit.

            java 对象头的长度
长度                      内容                              说明
32/64 bit               Mark Word                       存储对象的 hashCode 或锁信息等
32/64 bit               Class Metadata Address          存储到对象类型数据的指针
32/64 bit               Array Length                    数组的长度(如果当前对象是数组)

java 对象头里的 Mark Word 里默认存储对象的 HashCode, 分代年龄 和 锁标记位.
        32 位 JVM 的 Mark Word 的默认存储结构
锁状态         25 bit                  4 bit           1 bit 是否是偏向锁       2 bit 锁标志位
xxxx           对象的 hashCode        对象分代年龄            0                      01

在运行期间, Mark Word 里存储的数据会随着锁标志的变化而变化. Mark Word 可能变化为存储以下 4 种数据.
锁状态        |     25 bit             |     4 bit        |       1 bit           |        2 bit
              |  23 bit   |   2 bit    |                  |    是否是偏向锁       |       锁标志位
轻量级锁      |                     指向栈中锁记录的指针                           |         00
重量级锁      |                     指向互斥量(重量级锁)的指针                     |         10
GC 标记       |                       空                                          |         11
偏向锁        |  线程 ID  |   Epoch     | 对象分代年龄     |        1              |         01

在 64 位虚拟机下, Mark Word 是 64 bit 大小的, 其存储结构如表:
锁状态         25 bit          31 bit           1 bit              4 bit           1 bit               2 bit
                                               cms_free          分代年龄          偏向锁              锁标志位
无锁           unused         hashCode                                                0                  01
偏向锁         ThreadID(54 bit) Epoch(2 bit)                                          1                  01

锁的升级对比:
 java SE 1.6 为了减少获得锁和释放锁带来的性能消耗, 引入了 "偏向锁" 和 "轻量级锁", 在 Java SE 1.6 中, 锁 共有 4 种状态,
 级别从低到高依次是: 无锁状态, 偏向锁状态, 轻量级锁状态, 重量级锁状态. 这几个状态会随着竞争情况逐渐升级, 锁可以升级但不能降级,
 意味着 偏向锁 升级成 轻量级锁 后不能降级为 偏向锁. 这种 锁 升级不能降级的策略, 目的是为了提高 获得锁和释放锁 的效率.

1. 偏向锁.
   HotSpot 的作者经过研究发现, 大多数情况下, 锁 不仅不存在 多线程竞争, 而且总是由同一线程多次获得, 为了让线程获得锁的代价更低
   而引入了偏向锁. 当一个线程访问同步块并获取锁时, 会在 对象头 和 栈帧 中的锁记录里存储锁偏向的线程 ID, 以后该线程在进入和退出
   同步块时不需要进行 CAS 操作来加锁和解锁, 只需简单地测试以下对象头的 Mark Word 里是否存储着指向当前线程的偏向锁.
   如果测试成功, 表示线程已经获得了锁. 如果测试失败, 则需要再测试一下 Mark Word 中偏向锁的标识是否设置成 1(表示当前是偏向锁):
   如果没有设置, 则使用 CAS 竞争锁; 如果设置了, 则尝试使用 CAS 将对象头的偏向锁指向当前线程.
   1.1. 偏向锁的撤销
    偏向锁使用了一种等到竞争出现才释放锁的机制, 所以当其他线程尝试竞争偏向锁时, 持有偏向锁的线程才会释放锁. 偏向锁的撤销,
    需要等待全局安全点(在这个时间点上没有正在执行的字节码). 它会首先暂停拥有偏向锁的线程, 然后检查持有偏向锁的线程是否活着,
    如果线程不处在活动状态, 则将对象头设置成无锁状态; 如果线程仍然活着, 拥有偏向锁的栈会被执行, 遍历偏向对象的锁记录, 栈中的锁记录和
    对象头的 Mark Word 要么重新偏向于其他线程, 要么恢复到无锁或者 标记对象不适合作为偏向锁, 最后唤醒暂停的线程.
   1.2. 关闭偏向锁
    偏向锁在 java 6 和 java 7 里是默认启动的, 但是它在应用程序启动几秒钟之后才激活, 如果有必要可以使用 JVM 参数来关闭延迟
    -XX:BiasedLockingStartupDelay=0. 如果你确定应用程序里所有的锁通常情况下处于竞争状态, 可以通过 JVM 参数关闭偏向锁
    -XX:-UseBiasedLocking=false, 那么程序默认会进入轻量级锁状态.
2. 轻量级锁.
   2.1. 轻量级锁加锁
    线程在执行同步块之前, JVM 会先在当前线程的栈帧中创建用于存储锁记录的空间, 并将对象头中的 Mark Word 赋值到锁记录中, 官方称
    Displaced Mark Word. 然后线程尝试使用 CAS 将对象头中的 Mark Word 替换为指向锁记录的指针. 如果成功, 当前线程获得锁, 如果失败,
    表示其他线程竞争锁, 当前线程便尝试使用自旋来获取锁.
   2.2. 轻量级锁解锁
    轻量级解锁时, 会使用原子的 CAS 操作将 Displaced Mark Word 替换回到对象头, 如果成功, 则表示没有竞争发生. 如果失败, 表示当前锁存在
    竞争, 锁就会膨胀称重量级锁.
   因为自旋会消耗 CPU, 为了避免无用的自旋(比如获得锁的线程被阻塞住了), 一旦锁升级成重量级锁, 就不会再恢复到轻量级锁状态.
   当锁处于这个状态下, 其他线程视图获取锁时, 都会被阻塞住, 当持有锁的线程被释放之后会唤醒这些线程, 被唤醒的线程就会进行新一轮的夺锁之争.

                            锁的优缺点对比
锁                   优点                                          缺点                          适用场景
偏向锁           加锁和解锁不需要额外的消耗,                 如果线程间存在锁竞争,会带来         适用于只有一个线程访问同步块场景
              和执行非同步方法相比仅存在纳秒级的差距         额外的锁撤销的消耗
轻量级锁      竞争的线程不会阻塞, 提高了程序的响应速度        如果始终得不到锁竞争的线程,         追求响应时间, 同步块执行速度非常快
                                                            使用自旋会消耗 CPU
重量级锁      线程竞争不使用自旋, 不会消耗 CPU               线程阻塞, 响应时间缓慢              追求吞吐量, 同步块执行时间较长

原子操作的实现原理
   原子(atomic) 本意是 "不能被进行分割的最小粒子", 而原子操作(atomic operation) 意为 "不可被中断的一个或一系列操作".
   在多处理器上实现原子操作就变得有点复杂.
        相关 CPU 术语
术语名称                    英文                      解释
缓存行                     cache line                 缓存的最小操作单位
比较并交换                 compare and swap           CAS 操作需要输入两个数值, 一个旧值(期望操作前的值)和一个新值, 在操作期间先比较旧值有没发生变化,
                                                     如果没有发生变化, 才叫换成新值, 发生变化则不交换.
CPU 流水线                 CPU pipeline              CPU 流水线的工作方式就像工业生产上的装配流水线, 在 CPU 中由 5~6 个不同功能的电路单元组成一条
                                                     指令处理流水线, 然后将一条 X86 指令分成 5~6 步后再由这些电路单元分别执行, 这样就能实现一个 CPU
                                                     时钟周期完成一条指令, 因此提高 CPU 的运算速度.
内存顺序冲突              Memory order violation      内存顺序冲突一般是由假共享引起的, 假共享是指多个 CPU 同时修改同一个缓存行的不同部分而引起其中一个
                                                     CPU 的操作无效, 当出现这个内存顺序冲突时, CPU 必须清空流水线.

处理器如何实现原子操作:
   32 位 IA-32 处理器使用基于对 缓存加锁 或 总线加锁 的方式来实现多处理器之间的原子操作. 首先处理器会自动保证基本的内存操作的原子性.
   处理器保证从系统内存中读取或者写入一个字节是原子的, 意思是当一个处理器读取一个字节时, 其他处理器不能访问这个字节的内存地址.
   Pentium 6 和最新的处理器能自动保证单处理器对同一个缓存行里进行 16/32/64 位的操作是原子的, 但是复杂的内存操作处理器是不能
   自动保证其原子性的, 比如跨总线宽度, 跨多个缓存行和跨页表的访问. 但是, 处理器提供 总线锁定 和 缓存锁定 两个机制来保证复杂内存操作的原子性.
   1. 使用 总线锁 保证原子性
     第一个机制是通过 总线锁 保证原子性. 如果多个处理器同时对共享变量进行 读写改 操作(i++ 就是经典的读改写操作), 那么共享变量就会被多个处理器
     同时进行操作, 这样 读写改 操作就不是原子的, 操作完之后共享变量的值会和期望的不一致.
     想要保证 读写改 共享变量的操作是原子的, 就必须保证 CPU1 读写改 共享变量的时候, CPU2 不能操作缓存了该共享变量内存地址的缓存.
     处理使用 总线锁 就是来解决此问题的. 所谓 总线锁 就是使用处理器提供的一个 LOCK# 信号, 当一个处理器在总线上输出此信号时, 其他处理器的请求
     将被阻塞住, 那么该处理器可以独占共享内存.
   2. 使用 缓存锁 保证原子性
     第二个机制是通过缓存锁定来保证原子性. 在同一时刻, 我们只需保证对某个内存地址的操作是原子性即可, 但总线锁定把 CPU 和内存之间的通信锁住了,
     这使得 锁定期间, 其他处理器不能操作其他内存地址的数据, 所以总线锁定的开销比较大, 目前处理器在某些场合下使用 缓存锁定 替代总线锁定来进行优化.
    频繁使用的内存会缓存在处理器的 L1, L2 和 L3 高速缓存里, 那么原子操作就可以直接在处理器内部缓存中进行, 并不需要声明 总线锁, 在 Pentium 6 和目前
    的处理器中可以使用 "缓存锁定" 的方式来实现复杂的原子性.
    所谓 "缓存锁定" 是指内存区域如果被缓存在处理器的缓存行中, 并且在 Lock 操作期间被锁定, 那么当它执行锁操作回写到内存时, 处理器不在总线上声言 LOCK#
    信号, 而是修改内部的内存地址, 并允许它的缓存一致性机制来保证操作的原子性, 因为 缓存一致性机制会组织同时修改由两个以上处理器缓存的内存区域数据,
    当其他处理器回写已被锁定的缓存行的数据时, 会使缓存行无效.
但是有两种情况下处理器不会使用缓存锁定:
  condition 1. 当操作的数据不能被缓存在处理器内部, 或操作的数据跨多个缓存行(cache line)时, 则处理器会调用总线锁定.
  condition 2. 有些处理器不支持缓存锁定. 对于 Intel 486 和 Pentium 处理器, 就算锁定的内存区域在处理器的缓存行中也会调用总线锁定.
  针对以上两个机制, 我们通过 Intel 处理器提供了很多 Lock 前缀的指令来实现. 例如, 位测试和修改指: BTS, BTR, BTR; 交换指令 XADD, CMPXCHG,
  以及其他一些操作数和逻辑指令(如 ADD, OR)等, 被这些指令操作的内存区域就会加锁, 导致其他处理器不能同时访问它.


Java 语言中各种操作共享的数据分为 5 类:
   1. 不可变: immutable
     不可变对象一定是线程安全的,无论是对象的方法实现还是方法的调用者,都不需要再采取任何的线程安全保障措施.
     如果共享数据是一个基本数据类型,那么只要在定义时使用 final 关键字修饰它就可以保证它是不可变的.
     如果共享数据是一个对象,那就需要保证对象的行为不会对其状态产生任何影响才行. 比如 String 类的对象,它是一个典型的
     不可变对象,我们调用它的 substring(), replace() 和 concat() 等方法都不会影响它原来的值,只会返回一个新构造的字符串对象.
     保证对象行为不影响自己状态的途径有很多种,其中最简单的就是把对象中带有状态的变量都声明为 final, 这样在构造函数结束之后,
     它就是不可变的.
   2. 绝对线程安全
      一个类要达到 "不管运行时环境如何,调用者都不需要任何额外的同步措施" 通常需要付出很大的,甚至有时候是不切实际的代价.
      在 Java API 中标注自己是线程安全的类, 大多数都不是绝对的线程安全. 参见 juc.VectorTest
   3. 相对线程安全
      相对线程安全就是通常意义上所讲的线程安全,它需要保证这个对象单独的操作是线程安全的,在调用的时候不需要做额外的保障措施,
      但是对于一些特定顺序的连续调用,就可能需要在调用端使用额外的同步手段来保证调用的正确性.
      在 Java 语言中, 大部分线程安全类都属于这种类型, 例如 Vector, HashTable, Collections 的 synchronizedCollection() 方法包装的集合等.
   4. 线程兼容
      线程兼容是指对象本身并不是线程安全的,但是额可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用,
      通常说一个类不是线程安全地,绝大多数时候指的是这一种情况. Java API 中大部分的类都是属于线程兼容的,如与前面的 Vector 和
      Hashtable 相对应的集合类 ArrayList 和 HashMap 等.
   5. 线程对立
      线程对立是指无论调用端是否采取了同步措施,都无法在线程环境中并发使用的代码. 由于 Java 语言天生就具备多线程特性,线程对立这种
      排斥的代码是很少出现的,而且通常都是有害的,应当尽量避免.
      一个线程对立的例子是 Thread 类的 suspend() 和 resume() 方法,如果有两个线程同时持有一个线程对象,一个尝试去中断线程,另一个尝试去
      恢复线程,如果并发进行的话,无论调用时是否进行了同步,目标线程都是存在死锁风险的,如果 suspend() 中断的线程就是即将要执行 resume()
      的那个线程,那就肯定要产生死锁了. 也就是这个原因, 这两个方法已被废弃.


线程安全的实现方法
   1. 互斥同步 Mutual Exclusion & Synchronization
     同步指在多个线程并发访问共享数据时,保证共享数据在同一个时刻只被一个(或者是一些,使用信号量的时候) 线程使用. 而互斥是实现同步的
     一种手段,临界区(Critical Section), 互斥量(Mutex) 和信号量(Semaphore) 都是主要的互斥实现方式.
     互斥是因,同步是果; 互斥是方法,同步是目的.
     在 Java 中, 最基本的互斥同步手段就是 synchronized 关键字, synchronized 关键字经过编译之后,会在同步块的前后分别形成
     monitorenter 和 monitorexit 这两个字节码指令, 这两个字节码都需要一个 reference 类型的参数来指明要锁定和解锁的对象.
     如果 Java 程序中的 synchronized 明确指定了对象参数,那就是这个对象的 reference, 如果没有明确指定,那就根据 synchronized 修饰
     的是实例方法还是类方法, 去取对应的对象实例或 Class 对象来作为锁对象.
     根据虚拟机规范的要求,在执行 monitorenter 指令时,首先要尝试获取对象的锁. 如果这个对象没有被锁定,或者当前线程已经拥有了
     那个对象的锁,把锁的计数器加 1, 相应的, 在执行 monitorexit 指令时就会将锁计数器减一,当计数器为 0 时, 锁就被释放. 如果
     获取对象锁失败,那当前线程就要阻塞等待,直到对象锁被另外一个线程释放为止.
     在虚拟机规范对 monitorenter 和 monitorexit 的行为描述中,有两点是需要特别注意的. 首先, synchronized 同步块对同一线程来说
     是可重入的,不会出现自己把自己锁死的问题. 其次,同步块在已进入的线程执行完之前,会阻塞后面其他线程的进入.
     Java 的线程是映射到操作系统的原生线程之上的,如果要阻塞或唤醒一个线程,都需要操作系统来帮忙完成,这就需要从用户态转换到
     和心态中,因此状态转换需要耗费很多的处理器时间. 对于代码简单的同步块,状态转换消耗的时间有可能比用户代码执行的时间还要长.
     juc.ReentrantLock 与 synchronized 相似, 他们都具备一样的线程重入特性,只是代码写法上有点区别, 一个表现为 API 层面的
     互斥锁(lock() 和 unlock() 方法配合 try/finally 语句块来完成), 另一个表现为原生语法层面的互斥锁.
     不过,相比 synchronized, ReentrantLock 增加了一些高级功能, 主要有以下 3 项: 等待可中断,可实现公平锁,以及锁可以绑定多个条件.
     1). 等待可中断是指当持有锁的线程长期不释放锁定的时候,正在等待的线程可以选择放弃等待,改为处理其他事情,可中断特性对处理执行
        时间非常长的同步块很有帮助.
     2). 公平锁是指多个线程在等待同一个锁时,必须按照申请锁的时间顺序来依次获得锁; 而非公平锁则不保证这一点,在锁被释放时,任何
        一个等待的线程都有机会获得锁. synchronized 中的锁是非公平的, ReentrantLock 默认情况下也是非公平的,但可以通过带布尔值的
        构造函数要求使用公平锁.
     3). 锁绑定多个条件是指一个 ReentrantLock 对象可以同时绑定多个 Condition 对象, 而在 synchronized 中,锁对象的 wait() 和 notify()
        或 notifyAll() 方法可以实现一个隐含的条件,如果要和多于一个的条件关联的时候,就不得不额外地添加一个锁,而 ReentrantLock
        则无序这样做,只需要多次调用 newCondition 方法即可.
   2. 非阻塞同步
     互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题,因此这种同步也称为 阻塞同步(Blocking Synchronization).
     从处理问题的方式上说,互斥同步属于一种悲观的并发策略,总是认为只要不去做正确的同步措施(例如加锁),那就肯定会出现问题,
     无论共享数据是否真的会出现竞争,它都要进行加锁,用户态核心态转换,维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作.
     随着 硬件指令集 的发展,我们有了另外一个选择: 基于冲突检测的乐观并发策略,通俗的说,就是先进行操作,如果没有其他线程征用共享数据,
     那操作就成功了;如果共享数据有争用,产生了冲突,那就再采取其他的补偿措施(最常见的补偿措施就是不断地重试,直到成功为止),
     这种乐观地并发策略的许多实现都不需要把线程挂起,因此这种同步操作称为 非阻塞同步 Non-Blocking Synchronization.
     为什么说使用乐观并发策略需要 "硬件指令集的发展" 才能进行呢? 因为我们需要操作和冲突检测这两个步骤具备原子性,靠什么来保证呢?
     如果这里再使用互斥同步来保证就失去意义了,所以我们只能靠硬件来完成这件事情,硬件保证一个从语义上看起来需要多次操作的行为只通过
     一条处理器指令就能完成,这类指令常用的有:
      1) 测试并设置 Test-and-Set
      2) 获取并增加 Fetch-and-Increment
      3) 交换 Swap
      4) 比较并交换 Compare-and-Swap, CAS
      5) 加载链接/条件存储 Load-Linked/Store-Conditional, LL/SC
      CAS 指令需要有 3 个操作数, 分别是内存位置(在 Java 中可以简单理解为变量的内存地址,用 V 表示),
      旧的预期值(用 A 表示)和新值(用 B 表示). CAS 指令执行时,当且仅当 V 符合旧预期值 A 时, 处理器用新址 B 更新 V 的值,
      否则它就不执行更新, 但是无论是否更新了 V 的值, 都会返回 V 的旧值, 上述的处理过程是一个原子操作.
      在 JDK 1.5 之后, Java 程序中才可以使用 CAS 操作,该操作由 sun.mis.Unsafe 类里的 compareAndSwapInt() 和
      compareAndSwapLong() 等几个方法包装提供,虚拟机在内部对这些方法做了特殊处理,即时编译出来的结果就是一条平台相关的处理器
      CAS 指令, 没有方法调用的过程, 或者可以认为是无条件内联进去了.(这种被虚拟机特殊处理的方法称为 固有函数 Intrinsics, 类似的
      固有函数还有 Math.sin() 等).
      由于 Unsafe 类不是提供给用户调用的类(Unsafe.getUnsafe() 的代码中限制了只有启动类加载器 Bootstrap ClassLoader 加载的 Class
      才能访问它), 因此, 如果不采用反射手段, 我们只能通过其他的 Java API 来间接使用它, 如 JUC 包里的整数原子类, 其中的
      compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作.
   3. 无同步方案
     要保证线程安全,并不是一定要进行同步,两者没有因果关系.同步只是保证共享数据争用时的正确性的手段,如果一个方法本来
     就不涉及共享数据,那它自然就无需任何同步措施去保证正确性, 因此会有一些代码天生就是线程安全的.
     可重入代码(Reentrant Code): 也叫 纯代码(Pure Code), 可以在代码执行的任何时刻中断它,转而去执行另外一段代码(包括递归调用它本身),
     而在控制权返回后,原来的程序不会出现任何错误.相对线程安全来说,可重入性是更基本的特性,它可以保证线程安全,即所有的可重入代码
     都是线程安全的,但是并非所有的线程安全的代码都是可重入的.
     可重入代码有一些共同特征,例如不依赖存储在堆上的数据和公用的系统资源,用到的状态量都由参数中传入,不调用非可重入的方法等.
     可以通过一个简单的原则来判断代码是否具备可重入性: 如果一个方法,它的返回结果是可预测的,只要输入相同的数据,就都能返回相同的结果,
     那它就满足可重入性的要求,当然也就是线程安全的.
     线程本地存储 Thread Local Storage, 如果一段代码中所需要的数据必须与其他代码共享,那就看这些共享数据的代码是否能保证在同一个线程中执行.
     如果能保证,就可以把共享数据的可见范围限制在同一个线程之内,这样,无需同步也能保证线程之间不出现数据争用的问题.
     符合这种特点的应用并不少见,大部分使用哦个消费队列的架构模式(producer-consumer模式)都会将产品的消费过程尽量在一个线程中消费完,
     其中最重要的一个应用实例就是经典 Web 交互模型中的 "一个请求对应一个服务器线程" Thread-per-Request 的处理方式,这种处理方式的广泛
     应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题.
     Java 语言中,如果一个变量要被多线程访问,可以使用 volatile 关键字生命它为 "易变的"; 如果一个变量要被某个线程独享, Java 中就没有类似
     C++ 中 _declspec(thread) 这样的关键字,不过还是可以通过 java.lang.ThreadLocal 类来实现线程本地存储的功能. 每个线程的 Thread
     对象中都有一个 ThreadLocalMap 对象,这个对象存储了一组以 ThreadLocal.threadLocalHashCode 为键, 以本地线程变量为值的 K-V 值对,
     ThreadLocal 对象就是当前线程的 ThreadLocalMap 的访问入口, 每个 ThreadLocal 对象都包含了一个独一无二的 threadLocalHashCode 值,
     使用这个值就可以在线程 K-V 值对中找回对应的本地线程变量.

Java 如何实现原子操作.
    java 中通过 锁 和 循环 CAS 的方式来实现原子操作.
  1. 使用 循环 CAS 实现原子操作.
    JVM 中的 CAS 操作正是利用了处理器提供的 CMPXCHG 指令实现的. 自旋 CAS 实现的基本思路就是循环进行 CAS 操作直到
    成功为止. 以下代码实现了一个基于 CAS 线程安全的计数器方法 safe count 和一个非线程安全的计数器 count.
------------------------------------------------------------------------------------------------------------------------
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * ~~ Talk is cheap. Show me the code. ~~ :-)
 *
 * @author MiaoOne
 * @since 2019/12/20 9:22
 */
public class ConcurrentTest {
    private AtomicInteger i = new AtomicInteger(0);

    private int a = 0;

    public static void main(String[] args) {
        final ConcurrentTest cas = new ConcurrentTest();
        List<Thread> ts = new ArrayList<>(600);

        long start = System.currentTimeMillis();

        for (int i = 0; i < 100; i++) {
            Thread t = new Thread(() -> {
                for (int j = 0; j < 1000; j++) {
                    cas.count();
                    cas.safeCount();
                }
            });
            ts.add(t);
        }
        ts.forEach(Thread::start);

        // 等待所有线程执行完毕.
        ts.forEach(thread -> {
            try {
                thread.join();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        System.out.println(cas.a);
        System.out.println(cas.i.get());
        System.out.println(System.currentTimeMillis() - start + "ms");
    }

    /* 使用 CAS 实现线程安全计数器. */
    private void safeCount() {
        for (; ; ) {
            int a = this.i.get();
            boolean suc = this.i.compareAndSet(a, ++a);
            if (suc) {
                break;
            }
        }
    }

    /* 非线程安全计数器. */
    private void count() {
        a++;
    }
}
------------------------------------------------------------------------------------------------------------------------

CAS 实现原子操作的三大问题
   JUC 包中有一些并发框架也使用了自旋 CAS 的方式来实现原子操作, 比如 {@code java.util.concurrent.LinkedTransferQueue}
   的 {java.util.concurrent.LinkedTransferQueue.xfer()} 方法. CAS 虽然很高效地解决了原子操作, 但是 CAS 仍然存在三大问题.
   ABA 问题, 循环时间长开销大, 以及只能保证一个共享变量的源自操作.
   1. ABA 问题.
     因为 CAS 需要在操作值的时候, 检查值有没有发生变化, 如果没有发生变化, 但是如果一个值原来是 A, 变成了 B, 又变成了 A, 那么使用 CAS
     进行检查时会发现它的值没有发生变化, 但是实际上发生了变化. ABA 问题的解决思路就是使用版本号. 在变量前面追加上版本号, 每次变量更新的
     时候把版本号加 1, 那么 A->B->A 就会变成 1A->2B->3A. 从 java 1.5 开始, JDK 的 Atomic 包里提供了一个类 {java.util.concurrent.atomic.AtomicStampedReference}
     来解决 ABA 问题. 这个类的 compareAndSet 方法的作用是首先检查当前引用是否等于预期引用, 并且检查当前标志是否等于预期标志, 如果全部相等,
     则以原子方式将该引用和该标志的值设置为给定的更新值.
     java.util.concurrent.atomic.AtomicStampedReference.compareAndSet(V   expectedReference, // 预期引用.
                                                                      V   newReference, // 更新后的引用.
                                                                      int expectedStamp, // 预期标志.
                                                                      int newStamp) // 更新后的标志.
   2. 循环时间长开销大.
      自旋 CAS 如果长时间不成功, 会给 CPU 带来非常大的执行开销. 如果 JVM 能支持处理器提供的 pause 指令, 那么效率会有一定的提升.
      pause 指令有两个作用: 第一, 它可以延迟流水线执行指令(de-pipeline), 使 CPU 不会消耗过多的执行资源, 延迟的时间取决于具体实现的版本

----------------------------------------------------------------------------------------------------------------------------------
锁优化
  高效并发是从 JDK 1.5 到 JDK 1.6 的一个重要改进, HotSpot 虚拟机开发团队在这个版本上花费了大量的精力去实现各种锁优化技术,
  如 适应性自旋(Adaptive Spinning), 锁消除(Lock Elimination), 锁粗化(Lock Coarsening), 轻量级锁(Lightweight Locking)和
  偏向锁(Biased Locking)等,这些技术都是为了在线程之间更高效地共享数据,以及解决竞争问题,从而提高程序执行效率.
  1. 自旋锁和自适应自旋
   互斥同步 对性能最大地影响是阻塞的实现,挂起线程和回复线程的操作都需要转入内核态中完成,这些操作给系统的并发性能带来了很大的压力.
   同时,虚拟机的开发团队也注意到在许多应用上,共享数据的锁定状态只会持续很短的一段时间,为了这段时间去挂起和恢复线程并不值得.
   如果物理机器有一个以上的处理器,能让两个或以上的线程同时并行执行,我们就可以让后面请求锁的那个线程"稍等一下", 但不放弃处理器的执行时间,
   看看持有锁的线程是否很快就会释放锁. 为了让线程等待,我们只需让线程执行一个忙循环(自旋), 这项技术就是所谓的 自旋.
   自旋锁 在 JDK 1.4.2 引入,默认关闭,使用 -XX:+UseSpinning 参数来开启. JDK 1.6 以后默认开启.
   自旋锁等待不能代替阻塞,且先不说对处理器数量的要求,自旋等待本身虽然避免了线程切换的开销,但它是要占用处理器时间的,
   因此,如果锁被占用的时间很短,自旋等待的效果就会非常好. 反之,如果锁被占用的时间很长,那么自旋的线程只会白白消耗处理器资源,
   而不会做任何有用的工作,反而会带来性能上的浪费. 因此,自旋等待的时间必须要有一定的限度,如果自旋操过了限定的次数仍然没有成功获得锁,
   就应当使用传统的方式去挂起线程了. 自旋次数的默认值是 10 次,用户可以使用参数 -XX:PreBlockSpin 来更改.
   JDK 1.6 引入 自适应的自旋锁. 自适应 意味着自旋的时间不再固定了,而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定.
   如果在同一个锁对象上,自旋等待刚刚成功获得过锁,并且持有锁的线程正在运行中,那么虚拟机就会认为这次自旋也很有可能再次成功,进而它将允许
   自选等待继续相对更长的时间,比如 100 循环. 另外, 如果对于某个锁,自旋很少成功获得过,那在以后要获得这个锁时将可能省略掉自旋过程,
   以避免浪费处理器资源. 有了自适应自旋,随着程序运行和性能监控信息的不断完善,虚拟机对程序锁的状况预测就会越来越准确,虚拟机就会变得
   越来越 "聪明" 了.
  2. 锁消除
    锁消除 是指虚拟机即时编译期在运行时,对一些代码上要求同步,但是被检测到不可能存在共享数据竞争的锁进行消除. 锁消除的主要判定依据
    来源于 逃逸分析 的数据支持,如果判断在一段代码中,堆上的所有数据都不会逃逸出去从而被其他线程访问到,那就可以把它们当作栈上数据对待,
    认为它们是线程私有的,同步加锁自然就无法进行.
    注: 逃逸分析
      Java 虚拟机中的编译优化技术,它不是直接优化代码的手段,而是为其他优化手段提供依据的分析技术.
      逃逸分析的基本行为就是分析对象动态作用域: 当一个对象在方法中被定义后,它可能被外部方法所引用,例如作为调用参数传递到其他方法中,
      称为 方法逃逸. 甚至还有可能被外部线程访问到,譬如赋值给类变量或可以在其他线程中访问的实例变量,称为 线程逃逸.
      如果能证明一个对象不会逃逸到方法或线程之外,也就是别的方法或线程无法通过任何途径访问到这个对象,则可能为这个变量进行一些高效的优化:
      1) 栈上分配(Stack Allocation): Java 虚拟机中,在 Java 堆上分配创建对象的内存空间,Java 堆中的对象对于各个线程都是共享和可见的,
       只要持有这个对象的引用,就可以访问堆中存储的对象数据. 虚拟机的垃圾收集系统可以回收堆中不再使用的对象,但回收动作无论是筛选可回收对象,
       还是回收和整理内存都需要耗费时间. 如果确定一个对象不会逃逸出方法之外,那让这个对象在栈上分配内存将会是一个很不错的注意,
       对象所占用的内存空间就可以随栈帧而销毁. 在一般应用中,不会逃逸的局部对象所占的比例很大,如果能使用栈上分配,那大量的对象就会随着方法
       的结束而自动销毁了,垃圾收集系统的压力将会小很多.
      2) 同步消除(Synchronization Elimination): 线程同步本身是一个相对耗时的过程,如果逃逸分析能确定一个变量不会逃逸出线程,
        无法被其他线程访问,那这个变量的读写肯定就不会有竞争,对这个变量实施的同步措施也就可以消除掉.
      3) 标量替换(Scalar Replacement): 标量(Scalar)是指一个数据已经无法再分解成更小的数据来表示了, Java 虚拟机中的原始数据类型
        (int,long 等数置类型以及 reference 类型等)都不能再进一步分解,它们就可以称为标量. 相对的,如果一个数据可以继续分解,
        那它就称作聚合量(Aggregate), Java 中的对象就是最典型的聚合量. 如果把一个 Java 对象拆散,根据程序访问的情况,将其使用到
        的成员变量恢复原始类型来访问就叫做标量替换. 如果逃逸分析证明一个对象不会被外部访问,并且这个对象可以被拆散的化,
        那程序真正执行的时候将可能不创建这个对象,而改为直接创建它的若干个被这个方法使用到的成员变量来代替. 将对象拆分后,
        除了可以让对象的成员变量在栈上(栈上存储的数据,有很大的概率被虚拟机分配至物理机的高速寄存器中存储)分配和读写之外,
        还可以为后续进一步的优化手段创建条件.
  3. 锁粗化
    原则上,总是推荐将同步块的作用范围限制的尽量小--只在共享数据的实际作用域中才进行同步,这样是为了使得需要同步的操作数量
    尽可能变小,如果存在锁竞争,那等待锁的线程也可能尽快拿到锁.
    大部分情况下,上面的原则都是正确的,但是如果一系列的连续操作都对同一个对象反复加锁和解锁,甚至加锁操作是出现在循环体中的,
    那即使没有线程竞争,频繁地进行互斥同步操作也会导致不必要的性能损耗.
  4. 轻量级锁
    轻量级锁是 JDK 1.6 之中加入的新型锁机制,"轻量级" 是相对于使用操作系统互斥量来实现的传统锁而言的,因此传统的锁机制就称为
    "重量级"锁. 轻量级锁并不是用来替代重量级锁的,它的本意是在没有多线程竞争的前提下,减少传统的重量级锁使用操作系统互斥产生
    的性能消耗.
    ...
  5. 偏向锁
    JDK 1.6 引入的一项锁优化,它的目的是消除数据在无竞争情况下的同步原语,进一步提高程序的运行性能. 如果说轻量级锁是在无竞争
    的情况下使用 CAS 操作去消除同步使用的互斥量,那偏向锁就是在无竞争的情况下把整个同步都消除掉,连 CAS 操作都不做了.
    偏向锁的 "偏",就是偏心的 "偏",这个锁会偏向于第一个获得它的线程,如果在接下来的执行过程中,该锁没有被其他的线程获取,
    则持有偏向锁的线程将永远不需要再进行同步.




