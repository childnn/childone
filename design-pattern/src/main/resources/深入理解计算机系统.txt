Dennis Richie 丹尼斯·里奇
Brian Kernighan 布莱恩·克尼根
Linus Torvalds 林纳斯·托瓦兹

了解编译系统如何工作：
1. 优化程序性能：
    一个 switch 语句是否总是比一些列的 if-else 语句高效的多？
    一个函数调用的开销有多大?
    while 循环比 for 循环更有效吗？
    指针引用比数组索引更有效吗？
    为什么将循环求和的结果放到一个本地变量中，会比将其放到一个通过引用传递过来的参数中，运行起来快很多呢？
    为什么我们只是简单地重新排列以下算数表达式中的括号就能让函数运行得更快？
2. 理解链接时出现的错误：
    链接器报告说它无法解析一个引用，这是什么意思？
    静态变量和全局变量的区别是什么？
    如果你在不同的 C 文件中定义了名字相同的两个全局变量会发生什么？
    静态库和动态库的区别是什么？
    我们在命令行上排列库的顺序有什么影响？
    为什么有些链接错误直到运行时才会出现？
3. 避免安全漏洞：
    限制从不受信任的源接收数据的数量和格式。
    理解数据和控制信息存储在程序栈上的方式会引起的后果。
    堆栈原理和缓冲区溢出错误。

系统的硬件组成:
1. 总线.
   贯穿整个系统的是一组电子管道, 称总线.
   它携带信息字节并负责在各个部件间传递. 通常总线被设计成传送定长的字节块, 也就是 字(word).
   字中的字节数(即字长)是一个基本的系统参数, 各个系统中都不尽相同. 现在的大多数机器字长要么是 4 个字节(32位),
   要么是 8 个字节(64位).
2. I/O 设备.
    I/O 设备是系统与外部世界的联系通道. 我们的示例系统包括四个 I/O 设备: 作为用户输入的键盘和鼠标, 作为用户输出的显示器,
    以及用于长期存储数据和程序的磁盘驱动器(磁盘).
    每个 I/O 设备都通过一个控制器或适配器与 I/O 总线相连. 控制器和适配器之间的区别在于它们的封装方式.
    控制器 是 I/O 设备本身或者系统的主印制电路板(主板)上的芯片组.
    适配器 是一块插在主板插槽上的卡.
    它们的功能都是在 I/O 总线和 I/O 设备之间传递信息.
3. 主存.
    主存是一个临时存储设备, 在处理器执行程序时, 用来存放程序和程序处理的数据.
    从物理上来说, 主存是一组 动态随机存取存储器(DRAM: dynamic random access memory)芯片组成的.
    从逻辑上来说, 存储器是一个线性的字节数组, 每个字节都有其唯一的地址(数组索引), 这些地址是从零开始的.
4. 处理器.
    中央处理单元 CPU(central processing unit), 简称处理器, 是解释(或执行)存储在主存中指令的引擎.
    处理器的核心是一个大小为一个字的存储设备(或寄存器), 称为 程序计数器(PC: program counter).
    在任何时刻, PC 都指向主存中的某条机器语言指令(即含有该条指令的地址).
    从系统通电开始, 直到系统断电, 处理器一直在不断地执行 程序计数器 指向 地指令, 再更新程序计数器, 使其指向下一条指令.
    处理器 看上去是按照一个非常简单地指令执行模型来操作的, 这个模型是由指令集架构决定的.
    在这个模型中, 指令按照严格的顺序执行, 而执行一条指令包含执行一系列的步骤. 处理器从程序计数器指向的内存处读取指令,
    解释指令中的位, 执行该指令指示的简单操作, 然后更行 PC, 使其指向下一条指令, 而这条指令并不一定和在内存中刚刚执行的指令相邻.
    这样的简单操作并不多, 它们围绕着主存、寄存器文件(register file)和 算术/逻辑单元(ALU: arithmetic and logic unit) 进行.
    寄存器文件 是一个小的存储设备, 由一些单个字长的寄存器组成, 每个寄存器都有唯一的名字. ALU 计算新的数据和地址值.
    下面是一些简单操作的例子, CPU 在指令的要求下可能会执行这些操作.
     -- 加载: 从主存复制一个字节或者一个字到寄存器, 以覆盖寄存器原来的内容.
     -- 存储: 从寄存器复制一个字节或者一个字到主存的某个位置, 以覆盖这个位置上原来的内容.
     -- 操作: 把两个寄存器的内容复制到 ALU, ALU 对这两个做算术运算, 并将结果存放到一个寄存器中, 以覆盖该寄存器中原来的内容.
     -- 跳转: 从指令本身中抽取一个字, 并将这个字复制到程序计数器(PC)中, 以覆盖 PC 中原来的值.
     处理器 看上去是它的指令集架构的简单实现, 但是实际上现代处理器使用了非常复杂的机制来加速程序的执行. 因此, 我们将处理器的指令集
     架构和处理器的微体系结构区分开来: 指令集架构 描述的是每条机器代码指令的效果; 而 微体系结构 描述的是处理器实际上是如何实现的.

高速缓存: 静态随机访问存储器(SRAM: static random access memory)技术.


抽象: 计算机系统中的一个重大主题就是提供不同层次的抽象表示, 来隐藏实际实现的复杂性.
    1. 文件 是对 I/O 设备的抽象.
    2. 虚拟内存 是对 程序存储器(主存 和 磁盘) 的抽象. 虚拟内存 为每个进程提供了一个假象, 即每个进程都在独占地使用主存.
        每个进程看到的内存都是一致的, 称为 虚拟地址空间.
    3. 指令集架构 是对 处理器硬件的抽象. 使用这个抽象, 机器代码程序表现得就好像运行在一个一次只执行一条指令的处理器上.
        低层的硬件远比抽象描述的要复杂精细, 它并行地执行多条指令, 但又总是与那个简单有序的模型保持一致. 只要执行模型一样, 不同的
        处理器实现也能执行同样的机器代码, 而又提供不同的开销和性能.
    3. 进程 是对一个正在运行的程序的抽象 -- 包括 (处理器+主存+I/O设备). 在一个系统上可以同时运行多个进程, 而每个进程都好像在独占地使用硬件.
         并发运行: 一个进程的指令和另一个进程的指令是交错执行的.
         操作系统实现这种交错执行的机制称为 上下文切换.
         操作系统保持跟踪进程所需的所有状态信息, 这种状态就是 上下文, 包括许多信息, 比如 PC 和寄存器文件的当前值, 以及主存的内容.
            在任何时刻,单处理器系统都只能执行一个进程的代码. 当操作系统决定要把控制权从当前进程转移到某个新进程时,就会进行 上下文切换,
            即 保存当前进程的上下文、恢复新进程的上下文,然后将控制权传递到新进程. 新进程就会从它上次停止的地方开始.
       线程: 一个进程可以由多个称为 线程 的执行单元组成, 每个线程都运行在进程的上下文中, 并共享同样的代码和全局数据.
    4. 虚拟机 是对整个计算机的抽象, 包括操作系统、处理器和程序. 保证一个计算机可以运行不同的操作系统或同一操作系统的不同版本设计的程序.

文件.
-- 文件就是字节序列, 仅此而已. 每个 I/O 设备, 包括 磁盘、键盘、显示器, 甚至网络, 都可以看成是 文件.
   系统中的所有输入输出都是通过使用一个小组成为 Unix I/O 的系统函数调用读写文件来实现的.
   文件 这个简单而精致的概念是非常强大的, 因为它向应用程序提供了一个统一的视图, 来看待系统中可能含有的所有各式各样的 I/O 设备.

抽象 的使用是计算机科学中最为重要的概念之一. 例如, 为一组函数规定一个简单的应用程序接口(API: application programming interface)
    是一个很好的编程习惯, 程序员无需了解它内部的工作便可以使用这些代码. 不同的的编程语言提供不同形式和等级的抽象支持, 例如 Java 类的声明
    和 C 语言的函数原型.

:-)

Amdahl 定律. Gene Amdahl. Amdahl's law. 阿姆达尔定律.
-- 该定律的主要思想是, 当我们对系统的某个部分加速时, 其对系统整体性能的影响取决于该部分的重要性和加速程度.
   若系统执行某应用程序需要时间位 T(old). 假设系统某部分所需执行时间与该时间的比例位 α, 而该部分性能提升比例位 k.
   即该部分初始所需时间位 αT(old), 现在所需时间为 (αT(old))/k. 因此, 总的执行时间应为:
    T(new) = (1 - α)T(old) + (αT(old))/k = T(old)[(1 - α) + α/k]
    -- 由此, 可以计算加速度比 S = T(old)/T(new) 为
       S = 1/((1 - α) + α/k)
  eg: 系统的某个部分初始耗时比例为 60%(α = 0.6), 其加速比例因子为 3(k = 3). 则我们可以获得的加速比为 1/[0.4 + 0.6/3] = 1.67 倍.
    虽然我们对系统的一个主要部分做出了重大改进, 但是获得的系统加速比却明显小于这部分的加速比.
    这就是 Amdahl 定律的主要观点 -- 想要显著加速整个系统, 必须提升全系统中相当大的部分的速度.

并行和并发
-- 数字计算机的整个历史中, 有两个需求是驱动进步的持续动力: 一个是我们想要计算机做得更多, 另一个是我们想要计算机运行得更快.
   当处理器能够同时做更多的事情时, 这两个因素都会改进.
   并发 concurrency: 指一个同时具有多个活动的系统;
   并行 parallelism: 指用并发来使一个系统运行得更快.
-- 按照系统层次结构中由高到低得顺序重点强调三个层次:
   1. 线程级并发
       构建在 进程 这个抽象之上, 我们能够设计出同时有多个程序执行的系统, 这就导致了 并发. 使用 线程, 我们甚至能够
       在一个 进程 中执行多个 控制流.
       传统意义上, 这种 并发执行 只是 模拟 出来的, 是通过使一台计算机在它正在执行的 进程 间快速切换来实现的, 就好像
       一个杂耍艺人保持多个球在空中飞舞一样. 这种 并发 形式允许多个用户同时与系统交互, 例如, 当许多人想要从一个 Web 服务器
       获取页面时. 它还允许一个用户同时从十多个任务, 例如, 在一个窗口中开启 Web 浏览器, 在另一个窗口中运行字处理器,
       同时又播放音乐. 在以前, 即使处理器必须在多个任务间切换, 大多数实际的计算也都是由一个处理器来完成的. 这种配置称为
       单处理器系统.
   当构建一个由 单操作系统内核 控制的 多处理器 组成的系统时, 我们得到了一个 多处理器系统.
   -- 多处理器系统 包括 多核, 超线程(hyper-threading).
       -- 多核处理器 将多个 CPU(称为"核") 集成到一个集成到电路芯片上. 每个核都有自己的 L1 和 L2 高速缓存, 其中 L1 告诉缓存分为
          两个部分 -- 一个保存最近去到的指令, 另一个存放数据. 这些核共享更高层次的告诉缓存, 以及到主存的接口.
       -- 超线程, 有时称为 同时多线程(simultaneous multi-threading), 是一项允许一个 CPU 执行多个控制流的技术.
          它涉及 CPU 某些硬件有多个备份, 比如 程序计数器 和 寄存器文件, 而其他的硬件部分只有一份, 比如执行浮点算术运算的单元.
          常规的处理器需要大约 20,000 个时钟周期做不同线程间的转换, 而超线程的处理器可以在单个周期的基础上决定要执行哪个线程.
          这使得 CPU 能够更好地利用它地处理资源. 比如, 假设一个线程必须等到某些数据被装载到高速缓存中, 那 CPU 就可以继续去执行另一个线程.
          eg: Intel Core i7 处理器可以让每个核执行两个线程, 所以一个 4 核的系统实际上可以并行地执行 8 个线程.
       多处理器 的使用可以从两方面提高系统性能.
       首先, 它减少了在执行多个任务时模拟并发的需要. 正如前述, 即使是只有一个用户使用的个人计算机也需要并发地执行多个活动.
       其次, 它可以使应用程序运行得更快, 当然, 这必须要求程序是以多线程方式来书写的, 这些线程可以并行地高效执行.
   2. 指令级并行
       在较低的抽象层次上, 现代处理器可以同时执行多条指令的属性称为 指令级并行.
       其实每条指令从开始到结束需要长得多的时间, 大约 20 个或者更多周期,但是处理器使用了非常多的聪明技巧来同时处理多达 100 条指令.
       此即 流水线(pipelining)的使用, 在流水线中, 将执行一条指令所需要的活动划分为不同的步骤, 将处理器的硬件组织成一系列的阶段, 每个阶段执行一个步骤.
       这些阶段可以 并行 地操作, 用来处理不同指令地不同部分.
       如果处理器可以达到比一个周期一条指令更快的执行效率, 就称为 超标量(super-scalar)处理器.
   3. 单指令、多数据并行
       在最低层次上, 许多现代处理器拥有特殊的硬件, 允许一条指令产生多个可以并行执行的操作, 这种方式称为 单指令、多数据,
       即 SIMD(Single Instruction Multiple Data 单指令多数据流) 并行.

---
计算机系统由硬件和系统软件组成, 它们共同协作以运行应用程序. 计算机内部的信息被表示为一组组的为, 它们依据上下文有不同的解释方式.
程序被其他程序翻译成不同的形式, 开始时是 ASCII 文本, 然后被 编译器 和 链接器 翻译成二进制可执行文件.
处理器 读取并解释存放在主存里得二进制指令. 因为计算机花费大量得时间在内存、I/O 设备和 CPU 寄存器之间复制数据, 所以将系统中的存储设备
划分成层次结构 -- CPU 寄存器在顶部, 接着是多层的硬件高速缓存存储器、DRAM 主存和磁盘存储器.
---
现代计算机存储和处理的信息以二值信号表示. 这些微不足道的二进制数字, 或者称为 位(bit), 形成了数字革命的基础.
孤立地讲, 单个的位不是非常有用. 然而, 当把位组合在一起, 再加上某种解释(interpretation), 即赋予不同的可能位模式以含意,
我们就能表示任何有限集合的元素.
数字的表示:
-- 无符号(unsigned)编码: 基于传统的二进制表示法, 表示大于或者等于零的数字(非负数).
-- 补码(two's-complement)编码: 表示有符号整数的最常见的方式, 有符号整数就是可以为正或者为负的数字.
-- 浮点数(floating-point)编码: 表示实数的科学计数法的以 2 为基数的版本.

整数的表示虽然只能编码一个相对较小的数值范围, 但是这种表示是精确的; 而浮点数虽然可以编码一个较大的数值范围, 但是这种表示只是近似的.
通过研究数字的实际表示, 我们能够了解可以表示的值的范围和不同算术运算的属性. 为了使编写的程序能在全部数值范围内正确工作, 而且具有
可以跨越不同机器、操作系统和编译器组合的可移植性, 了解这种属性是非常重要的. 大量计算机的安全漏洞都是由于计算机算术运算的微妙细节引发的.

信息存储：
    大多数计算机使用 8 位的块, 或者 字节(byte), 作为最小的可寻址的内存单位, 而不是访问内存中 单独的位.
    机器级程序将内存视为一个非常大的字节数组, 称为 虚拟内存(virtual memory).
    内存的每个字节都有一个唯一的数字来标识, 称为它的 地址(address), 所有可能地址的集合就称为 虚拟地址空间(virtual address space).
    顾名思义, 这个虚拟地址空间只是一个展现给机器级程序的概念性映像. 实际的实现是将 动态随机访问存储器(DRAM)、闪存、磁盘存储器、特殊硬件和操作系统软件
    结合起来, 为程序提供一个看上去统一的字节数组.

指针: C 语言的一个重要特性. 它提供了引用数据结构(包括数组)的元素的机制. 与变量类似, 指针也有两个方面: 值和类型.
    它的值表示对象的位置, 而它的类型表示那个位置上所存储对象的类型(比如 整数或者浮点数).
    &x: "取地址" 运算符 & 创建一个指向保存变量 x 的位置的指针.

十进制 --> 十六进制(0x..) --> 二进制
当值 x 是 2 的非负整数 n 次幂时, 也就是 x = 2^n, 我们可以很容易地将 x 写成十六进制形式, 只要记住 x 的二进制表示就是 1 后面跟 n 个 0.
十六进制数字 0 代表 4 个二进制 0. 所以, 当 n 表示成 i + 4j 的形式, 其中 0 <= i <= 3, 我们可以把 x 写成开头的十六进制数字为
    1(i = 0), 2(i = 1), 4(i = 2) 或者 8(i = 3), 后面跟随着 j 个十六进制的 0.
   比如, x = 2048 = 2^11, 我们有 n = 11 = 3 + 4 * 2, 从而得到十六进制表示 0x800.

字数据大小
    每台计算机都有一个字长(word size), 指明指针数据的标称大小(nominal size).
    因为虚拟地址是以这样一个字来编码的, 所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小. 也就是说, 对于一个字长为 w 位的机器而言,
    虚拟地址的范围位 0 ~ 2^w - 1, 程序最多访问 2^w 个字节.
寻址和字节顺序
    对于跨越多字节的程序对象, 我们必须建立两个规则: 这个对象的地址是什么, 以及在内存中如何排列这些字节.
    在几乎所有的机器上, 多字节对象都被存储为连续的字节序列, 对象的地址为所使用字节中最小的地址. 例如, 假设一个类型为 int 的变量 x 的地址
    为 0x100, 也就是说, 地址表达式 &x 的值为 0x100. 那么, (假设数据类型 int 为 32 位表示) x 的 4 个字节将被存储在内存的 0x100, 0x101, 0x102 和 0x103 位置.
小端法 little endian: 在内存中按照从最低有效字节到最高有效字节的顺序存储对象(地址的低位 对应 数据的低位).
大端法 big endian: 在内存中按照从最该有效字节到最低有效字节的顺序存储(地址的高位 对应 数据的高位).
    eg: 假设变量 x 的类型为 int, 位于地址 0x100 处, 它的十六进制为 0x01234567. 地址范围 0x100 ~ 0x103 的字节顺序依赖于机器的类型.
        大端法:
            地址  0x100  0x101  0x102  0x103
            数据   01     23     45      67
        小端法:
            地址  0x100  0x101  0x102  0x103
            数据   67     45     23     01
     注意: 在字 0x01234567 中, 高位字节的十六进制值为 0x01, 而低位字节值为 0x67.

反汇编器: disassembler. 一种确定可执行程序文件所表示的指令序列的工具.

表示字符串
    C 语言中 字符串被编码为一个以 null(其值为 0)字符结尾的字符数组.
    'a' ~ 'z' 的 ASCII 码为 0x61 ~ 0x7A (97 ~ 112).


逻辑符号:
    ~: 非, NOT
    &: 与, AND
    |: 或, OR
    ^: 异或, exclusive-or. 当二者有真且不同时为真时, 结果为真.

逻辑右移与算术右移
   逻辑右移: 左端补 0.
   算术右移: 左端补最高有效位的值(符号位).
 eg:
    操作                             值
   参数 x                     [0110 0011] [1001 0101]
   x << 4                     [0011 0000] [0101 0000]
   x >> 4 (逻辑右移)          [0000 0110] [0000 1001]
   x >> 4 (算术右移)          [0000 0110] [1111 1001]
 注:
  1. C 语言标准没有明确定义对于 有符号数 应该使用哪种类型的右移 -- 算术右移或者逻辑右移都可以.
     另一方面, 对于无符号数, 右移必须是 逻辑的.
  2. Java 对于如何进行右移有明确的定义. 表达式是 x >> k 会将 x 算术右移 k 个位置,
     而 x >>> k 会对 x 做逻辑右移.

整数表示
    符号           类型              含义              全名
    B2T            函数          二进制转补码         binary to two's-complement
    B2U            函数          二进制转无符号数     binary to unsigned
    U2B            函数          无符号数转二进制     unsigned to binary
    U2T            函数          无符号转补码
    T2B            函数          补码转二进制
    T2U            函数          补码转无符号数
    TMin           常数          最小补码值
    TMax           常数          最大补码值
    UMax           常数          最大无符号数
      注: B -- binary                二进制
          T -- two's complement      补码
          U -- unsigned              无符号

C, C++ 都支持有符号(默认)和无符号数. Java 只支持有符号数.

补码编码(B2T: binary to two's-complement)
    补码 two's-complement: 最常见的 有符号数 的计算机表示方式.
    在这个定义中, 将字的最高有效位解释为 负权(negative weight).
    最高有效位 也称为 符号位, 它的 "权重" 为 无符号表示中权重的负数.
    符号位被设置为 1 时, 表示值为 负, 而当设置为 0 时, 值为非负.

C 语言标准并没有要求要用补码形式来表示有符号整数, 但是几乎所有的机器都是这么做的.

反码: Ones' Complement
    直接取反. -- 补码是取反加一(最高位的权重的负数形式).
原码: Sign-Magnitude
    最高有效位是符号位, 用来确定剩下的位应该取 负权还是正权.
 这两种表示方法都有一个奇怪的属性, 那就是对于数字 0 有两种不同的编码方式.
 这两种表示方法, 把 [00...0] 都解释为 +0. 而值 -0 在 原码 中表示为 [00...0],
 在 反码 中表示为 [11...1]. 虽然过去生产过基于 反码表示的机器, 但是几乎所有的现代机器都使用补码.
 我们将看到在浮点数中有使用 原码编码.
 注: 补码(Two's complement) 和 反码(Ones' complement) 中撇号的位置是不同的.
    术语 补码 来源于这样一个情况, 对于 非负数 x, 我们用 2^w - x (这里只有一个 2)来计算 -x 的 w 位表示.
    术语 反码 来源于这样一个属性, 我们用 [111...1] - x (这里有很多个 1)来计算 -x 的反码表示.

C 语言中的有符号数和无符号数
    C 语言支持所有整型数据类型的有符号和无符号运算. 尽管 C 语言标准没有指定有符号数要采用某种表示, 但是
    几乎所有的机器都是用补码. 通常, 大多数数字都默认为是 有符号的. 例如, 当声明一个像 12345 或者 0x1A2B 这样的常量时,
    这个值就被认为是 有符号的. 要创建一个 无符号常量, 必须加上后缀字符 "U" 或者 "u", 例如, 12345U 或者 0x1A2Bu.
    C 语言允许无符号数和有符号数之间的转换. 虽然 C 标准没有精确规定应该如何进行这种转换, 但大多数系统遵循的原则是
    低层的位标识保持不变. 因此, 在一台采用 补码的机器上, 当从无符号数转换为有符号数时, 效果就是应用函数 U2T, 而从有符号数
    转换为 无符号数时, 就是应用函数 T2U.
    当用 printf 输出数值时, 分别用指示符 %d, %u, %x 以有符号十进制, 无符号十进制和十六进制格式输出一个数字.
    由于 C 语言对同时包含有符号和无符号数表达式的这种处理方式, 出现了一些奇特的行为. 当执行一个运算时, 如果它的一个运算数
    是 有符号的, 而另一个是 无符号的, 那么 C 语言会隐式地将 有符号参数 强制类型转换为 无符号数, 并假设这两个数都是 非负的,
    来执行这个运算. 这种方法对于标准的算术运算来说并无多大差异, 但是对于像 < 和 > 这样的关系运算符来说, 它会导致非直观的结果.

扩展一个数字的位表示
    一个常见的运算是在不同字长的整数之间转换, 同时又保持数值不变. 当然, 当目标数据类型太小以至于不能表示想要的值时, 这根本就是不可能的.
    然而, 从一个较小的数据类型转换到一个较小的类型, 应该总是可能的.
    要将一个 无符号数 转换为一个更大的数据类型, 我们只要简单地在表示的开头添加 0. 这种运算称为 零扩展(zero extension).
    要将一个 补码数字 转换为一个更大的数据类型, 可以执行一个 符号扩展(sign extension), 在表示中添加最高有效位的值.

GCC C 语言编译器以汇编代码的形式产生输出, 汇编代码是机器代码的文本表示, 给出程序中的每一条指令.
然后 GCC 调用 汇编器 和 链接器, 根据 汇编代码 生成可执行的 机器代码.

为甚要花时间学习机器代码?
 即使 编译器 承担了生成汇编代码的大部分工作, 对于严谨的程序员来说, 能够阅读和理解 汇编代码 仍是一项重要的技能.
 以适当的命令行选项调用编译器, 编译器就会产生一个以汇编代码形式表示的输出文件. 通过阅读 汇编代码, 我们能够理解
 编译器 的优化能力, 并分析代码中隐含的低效率.
 视图最大化一段关键代码性能的程序员, 通常会尝试源代码的各种形式, 每次编译并检查产生的汇编代码, 从而了解程序将要
 运行的效率如何. 此外, 也有些时候, 高级语言提供的抽象层会隐藏我们想要了解的程序的运行时行为.
 例如, 用线程包写并发程序时, 了解不同的程序是如何共享程序数据或保持数据私有的, 以及准确知道如何在哪里访问共享数据,
 都是很重要的.
 这些信息在机器代码级是可见的.
 程序遭到攻击(使得恶意软件侵扰系统)的许多方式中, 都涉及程序存储运行时控制信息的方式的细节. 许多攻击利用了系统程序中
 的漏洞重写信息, 从而获得了系统的控制权. 了解这些漏洞是如何出现的, 以及如何防御他们, 需要具备程序机器级表示的知识.
 程序员学习汇编代码的需求随着时间的推移也发生了变化, 开始时要求程序员能直接用汇编语言编写程序, 现在则要求他们能够阅读
 和理解编译器产生的代码.

机器级代码
   对于机器级编程来说, 其中两种抽象尤为重要.
   第一种是由 指令集体系结构(指令集架构)(Instruction Set Architecture, ISA) 来定义机器级程序的格式和行为, 它定义了
       处理器状态、指令的格式, 以及每条指令对状态的影响.
   第二种抽象是, 机器级程序 使用的内存地址是虚拟地址, 提供的内存模型看上去是一个非常大的字节数组.
       存储器系统的实际实现是将多个硬件存储器和操作系统软件组合起来.
   在整个编译过程中, 编译器会完成大部分的工作, 将把用 C 语言提供的相对比较简单的执行模型表示的程序转化成处理器执行的
   非常基本的指令. 汇编代码表示非常接近于机器代码. 与机器代码的二进制格式相比, 汇编代码的主要特点是它用 可读性更好的
   文本格式表示. 能够理解汇编代码以及它与原始 C 代码的联系, 是理解计算机如何执行程序的关键一步.

关于指针:
    long x = *xp; -- 读.
    将都存储在 xp 所指位置中的值, 并将它存放到名字为 x 的局部变量中. 这个读操作称为 指针的间接引用(pointer dereferencing)
    C 操作符 * 执行指针的间接引用.
    *xp = y; -- 写.
    将参数 y 的值写到 xp 所指的位置. 这也是指针间接引用的一种形式(所以又操作符 *), 但是它表明的是一个 写操作, 因为它在赋值语句的左边.
    -------------------------------------------------
    long a = 4;
    long = exchange(&a, 3);
    printf("a = %ld, b = %ld\n", a, b);

    long exchange(long *xp, long y) {
        long x = *xp;
        *xp = y;
        return x;
    }
    ---------------------------------------------------
    C 操作符 & (称为"取址"操作符)创建一个指针, 在本例中, 该指针指向保存局部变量 a 的位置.
    然后, 函数 exchange 将用 3 覆盖存储在 a 中的值, 但是返回原来的值 4 作为函数的值. 注意如何
    将指针传递给 exchange, 它能修改存在某个远处位置的数据.

栈操作说明. 根据惯例, 我们的栈是倒过来画的, 因而栈 "顶" 在底部. x86-64 中, 栈向低地址方向增长, 所以压栈是
减小栈指针(寄存器 %rsp)的值, 并将数据存放到内存中, 而出栈是从内存中读数据, 并增加栈指针的值.

指针运算
   C 语言允许对指针进行运算, 而计算出来的值会根据该指针引用的数据类型的大小进行伸缩。 也就是说,
   如果 p 是一个指向类型为 T 的数据的指针, p 的值为 x(下标p), 那么表达式 p + i 的值为 x(下标p) + L·i,
   这里 L 是数据类型 T 的大小.
   单操作数操作符 & 和 * 可以产生指针和间接引用指针. 也就是, 对于一个表示某个对象的表达式 Expr, &Expr 是
   给出该对象地址的一个指针. 对于一个表示地址的表达式 AExpr, *AExpr 给出该地址处的值. 因此, 表达式 Expr 与
   *&Expr 是等价的. 可以对数组和指针应用数组下标操作. 数组引用 A[i] 等同于表达式 *(A + i). 他计算第 i 个数组元素的\
   地址, 然后访问这个内存位置.

异质的数据结构
    C 语言提供了两种将不同类型的对象组合到一起创建数据类型的机制: 结构(structure), 用关键字 struct 来声明,
    将多个对象集合到一个单位中; 联合(union), 用关键字 union 来声明, 允许用几种不同的类型来引用一个对象.
  结构
    C 语言的 struct 声明创建一个数据类型, 将可能不同类型的对象聚合到一个对象中. 用名字来引用结构的各个组成部分.
    类似于数组的实现, 结构的所有组成部分都存放在内存中一段连续的区域内, 而指向结构的指针就是结构第一个字节的地址.
    编译器维护关于每个类型的信息, 指示每个字段(field)的字节偏移. 它以这些偏移作为内存引用指令中的位移, 从而产生对结构元素的引用.

    C 语言提供的 struct 数据类型的构造函数(constructor)与 C++ 和 Java 的对象最为接近. 它允许程序员在一个数据结构中保存
    关于某个实体的信息, 并用名字来引用这些信息.

  联合
    联合提供了一种方式, 能够规避 C 语言的类型系统, 允许以多种类型来引用一个对象. 联合声明的语法与结构的语法一样, 只不过语义相差
    比较大.

理解指针
   1. 每个指针都对应一个类型. 这个类型表明该指针指向的是哪一类对象.
       int *ip;
       char **cpp;
       变量 ip 是一个指向 int 类型对象的指针, 而 cpp 指针指向的对象自身就是一个指向 char 类型对象的指针. 通常, 如果对象类型为 T,
       那么指针的类型为 T *. 特殊的 void * 类型代表通用指针. 比如说, malloc 函数返回一个通用指针, 然后通过显示强制类型转换或者
       赋值操作那样的隐式强制类型转换, 将它转换成一个有类型的指针. 指针类型不是机器代码中的一部分; 它们是 C 语言提供的一种抽象,
       帮助程序员避免寻址错误.
   2. 每个指针都有一个值.
       这个值是某个指定类型的对象的地址. 特殊的 NULL(0) 值表示指针没有指向任何地方.
   3. 指针用 "&" 运算符创建.
       这个运算符可以应用到任何 lvalue 类的 C 表达式上, lvalue 意指可以出现赋值语句左边的表达式. 这样的例子包括变量以及结构、
       联合和数组的元素。
   4. * 操作符用于间接引用指针.
       其结果是一个值, 它的类型与该指针的类型一致. 间接引用是用内存引用来实现的, 要么是存储到一个指定的地址, 要么是从指定的地址读取.
   5. 数组与指针紧密联系.
       一个数组的名字可以像一个指针变量一样引用(但是不能修改). 数组引用(a[3])与指针运算和间接引用(*(a + 3))有一样的效果.
       数组引用和指针运算都需要用对象大小对偏移量进行伸缩. 当我们写表达式 p + i, 这里指针 p 的值为 p, 得到的地址计算为 p + L·i,
       这里 L 是与 p 相关联的数据类型的大小.
   6. 将指针从一种类型强制转换成另一种类型, 只改变它的类型, 而不改变它的值.
       强制类型转换的一个效果是改变指针运算的伸缩. 例如, 如果 p 是 char * 类型的指针, 它的值为 p, 那么表达式 (int * )p + 7 计算为
       p + 28, 而 (int *)(p + 9) 计算为 p + 7. (强制类型转换的优先级高于加法)
   7. 指针也可以指向函数.
       这提供了一个很强大的存储和像代码传递引用的功能, 这些引用可以被程序的某个其他部分调用.
       例如, 如果我们有一个函数, 用下面这个原型定义:
       int fun(int x, int *p);
       然后, 我们可以声明一个指针 fp, 将它赋值为这个函数, 代码如下:
       int (*fp)(int, int *);
       fp = fun;
       然后用这个指针来调用这个函数:
       int y = 1;
       int result = fp(3, &y);
       函数指针的值是该函数机器代码表示中第一条指令的地址.

Just-in-time compilation 即(及?)时编译: java, 动态地将字节代码序列翻译成机器指令.
    当代码要执行多次时(例如在循环中), 这种方法执行起来更快. 用字节代码作为程序的低级表示,
    优点是相同的代码可以在许多不同的机器上执行.

---------------------------------------------------------------
处理器体系结构 -- 硬件设计.
ISA: Instruction-Set Architecture 指令集体系结构.
    一个处理器支持的指令和指令的字节级编码.
    ISA 在编译器编写者和处理器设计人员之间提供了一个概念抽象层, 编译器编写者只需要知道允许哪些指令, 以及它们是如何编码的;
    而处理器设计者必须建造出执行这些指令的处理器.
现代处理器的实际工作方式可能跟 ISA 隐含的计算模型大相径庭. ISA 模型看上去应该是 顺序指令执行, 也就是先取出一条指令, 等到它执行完毕,
    再开始下一条. 然而, 与一个时刻只执行一条指令相比, 通过同时处理多条指令的不同部分, 处理器可以获得更高的性能. 为了保证处理器能得到同顺序
    执行相同的结果, 人们采用了一些特殊的机制. 在计算机科学中, 用巧妙的方法在提高性能的同时又保持一个更简单、更抽象模型的功能, 这种思想是众所周知的.
你可能永远都不会自己设计处理器. 这是专家们的任务, 他们工作在全球不到 100 家的公司里. 那么为什么你还应该了解处理器设计呢?
   1. 从智力方面来说, 处理器设计是非常有趣而且很重要的.
      学习事物是怎样工作的有其内在价值. 了解作为计算机科学家和工程师日常生活一部分的一个系统的内部工作原理(特别是对很多人来说这还是个谜), 是件
      格外有趣的事情. 处理器设计包括许多好的工程实践原理. 它需要完成复杂的任务, 而结构又要尽可能简单和规则.
   2. 理解处理器如何工作能帮助理解整个计算机系统如何工作的.
   3. 虽然很少有人设计处理器, 但是许多人设计包含处理器的硬件系统.
   4. 你的工作可能就是处理器设计.

HCL: Hardware Control Language 硬件控制语言.

编写高效程序需要做到以下几点:
    1. 必须选择一组适当的算法和数据结构;
    2. 必须编写出编译器能够有效优化以转换成高效代码的源代码.
  C 语言的有些特性, 例如执行指针运算和强制类型转换的能力, 使得编译器很难对它进行优化.
 程序优化的第一步就是消除不必要的工作, 让代码尽可能有效地执行所期望的任务. 这包括消除不必要的函数调用、条件测试
    和内存引用. 这些优化不依赖于目标机器的任何具体属性.
 研究程序的汇编代码表示 是理解编译器以及产生的代码会如何运行的最有效手段之一.

表示程序性能:
    CPE: Cycles Per Element, 度量标准每元素的周期, 作为一种表示程序性能并知道我们改进代码的方法.
    CPE 这种度量标准帮助我们在更细节的级别上理解迭代程序的循环性能.


存储器系统: memory system
    高速缓存存储器 -- cache memory
    主存储器 -- main memory
    RAM: random-access memory 随机访问存储器.
        -- 静态: SRAM  static
        -- 动态: DRAM  dynamic
        静态比动态更快, 更贵.
        SRAM 用来作为高速缓存存储器, 既可以在 CPU 芯片上, 也可以在片下.
        DRAM 用来作为主存以及图形系统的帧缓冲区.
        一般的, 一个桌面系统的 SRAM 不会超过几兆字节, 但是 DRAM 却有几百或几千兆字节.
        -- SRAM 将每个位存储在一个 双稳态的(bistable) 存储器单元里. 每个单元是用一个六晶体管电路来实现的.
        这个电路有这样一个属性, 它可以无限期地保持在两个不同的电压配置(configuration)或状态(state)之一.
        其他任何状态都是不稳定的 -- 从不稳定状态开始, 电路会迅速地转移到两个稳定状态中的一个.
        由于 SRAM 存储器单元的双稳态特性, 只要有电, 它就会永远地保持它的值. 即时有干扰来扰乱电压, 当干扰消除时, 电路就会恢复到稳定值.
        -- DRAM 将每个位存储为对一个电容的充电. 这个电容非常小, 通常只有大约 30 毫微微法拉.
    ROM: read-only memory
        如果断电, DRAM 和 SRAM 会丢失它们的信息, 从这个意义上说, 它们是易失的(volatile). 另一方面, 非易失性存储器(nonvolatile memory)
        即时是在关电后, 仍然保持着它们的信息. 现在很多种非易失性存储器. 由于历史原因, 虽然 ROM 中有的类型既可以读也可以写, 但是它们整体上都被称为
        只读存储器(ROM).
        ROM 是以它们能够被重编程(写)的次数和对它们进行重编程所用的机制来区分的.
        PROM(Programmable ROM, 可编程 ROM) 只能被编程一次. PROM 的每个存储器单元有一种 熔丝(fuse), 只能用高电流熔断一次.
        EPROM(Erasable Programmable ROM, 可擦写可编程 ROM) 有一个透明的石英窗口, 允许光到达存储单元. 紫外线光照射过窗口, EPROM 单元
          就被清除为 0. 对 EPROM 编程是通过使用一种把 1 写入 EPROM 的特殊设备来完成的. EPROM 能够被檫除和重编程的次数的数量级可以达到 1000 次.
          电子可檫除 PROM(Electrically Erasable PROM, EEPROM) 类似于 EPROM, 但是它不需要一个物理上独立的编程设备, 因此可以直接在印刷电路卡上编程.
          EEPROM 能够被编程的次数的数量级可以达到 10^5 次.
        闪存(flash memory) 是一类非易失性存储器, 基于 EEPROM, 它已经成为一种重要的存储技术. 闪存无处不再, 为大量的电子设备提供快速而持久的非易失性存储.
        固态硬盘(Solid State Disk, SSD) 一种新型的基于山村的磁盘驱动器, 它能提供相对传统旋转磁盘的一种更快、更强健和更低能耗的选择.
      存储在 ROM 设备中的程序通常被称为 固件(firmware). 当一个计算机系统通电以后, 它会运行存储在 ROM 中的固件. 一些系统在固件中提供了少量基本的输入和
       输出函数--例如 PC 的 BIOS(basic input-output system, 基本输入/输出系统)例程. 复杂的设备, 像图形卡和磁盘驱动控制器, 也依赖固件翻译来自 CPU 的 I/O 请求.
    --------------------------------------------------------------
    访问主存
        数据流通过称为 总线(bus) 的 共享电子电路 在处理器和 DRAM 主存之间来来回回. 每次 CPU 和主存之间的数据传送都是通过一系列步骤来完成的,
        这些步骤称为 总线事务(bus transaction).
        读事务(read transaction) 从主存传送数据到 CPU.
        写事务(write transaction) 从 CPU 传送数据到主存.
        总线是一组并行的导线, 能携带 地址、数据和控制信号. 取决于总线的设计, 数据和地址信号可以共享同一组导线, 也可以使用不同的.
        同时, 两个以上的设备也能共享同一总线. 控制线携带的信号会同步事务, 并标识出当前正在被执行的事务的类型.
        例如, 当前关注的这个事务是到主存的吗? 还是到存储如磁盘控制器这样的其他 I/O 设备? 这个事务是读还是写? 总线上的信息是地址还是数据项?
     计算机系统的配置:
        CPU 芯片, I/O 桥接器(I/O bridge) 芯片组(其中包括内存控制器), 组成主存的 DRAM 内存模块.
        这些部件由一对总线连接起来, 其中一条总线是 系统总线(System Bus), 它连接 CPU 和 I/O 桥接器,
        另一条是内存总线(Memory Bus), 它连接 I/O 桥接器和主存.
        I/O 桥接器将系统总线的电子信号翻译成内存总线的电子信号.
        I/O 桥也将系统总线和内存总线连接到 I/O 总线, 将磁盘和图形卡这样的 I/O 设备共享 I/O 总线.
    CPU 指令:
      movq A,%rax
       -- 地址 A 的内容被加载到 寄存器 %rax 中. CPU 芯片上称为 总线接口(bus interface) 的电路在总线上发起 读事务.
          读事务是由三个步骤组成的. 首先, CPU 将地址 A 放到系统总线上. I/O 桥将信号传递到内存总线. 接下来, 主存感觉到内存总线
          上的地址信号, 从内存总线读地址, 从 DRAM 取出数据字, 并将数据写到内存总线. I/O 桥将内存总线信号翻译成系统总线信号,
          然后沿着系统总线传递. 最后, CPU 感觉到系统总线上的数据, 从总线上读数据, 并将数据复制到寄存器 %rax.
      movq %rax,A
        -- 寄存器 %rax 的内容被写到地址 A, CPU 发起写事务. 同样有三个基本步骤.
           首先, CPU 将地址放到系统总线上. 内存从内存总线读出地址, 并等待数据到达.
           接下来, CPU 将 %rax 中的数据字复制到系统总线. 最后, 主存从内存总线读出数据字, 并且将这些位存储到 DRAM 中.
    磁盘存储:
       磁盘 是广为应用的保存大量数据的存储设备, 存储数据的数量级可以达到几百到几千兆字节, 而基于 RAM 的存储器只能有几百或
       几千兆字节. 不过, 从磁盘上读取信息的时间为毫秒级, 比从 DRAM 读慢了 10 万倍, 比从 SRAM 读慢了 100 万倍.
       1. 磁盘构造:
        磁盘是由 盘片(platter)构成的. 每个盘片有两面或者称为 表面(surface), 表面覆盖着磁性记录材料. 盘片中央有一个可以旋转
        的主轴(spindle), 它使得盘片固定的旋转速率(rotational rate) 旋转, 通常是 5400~15000/min(Revolution Per Minute, PRM).
        磁盘通常包含一个或多个这样的盘片, 并封装在一个密封的容器内.
        磁盘的表面由一组称为 磁道(track) 的同心圆组成. 每个磁道被划分为 一组扇区(sector). 每个扇区包含相等数量的数据位(通常 512 字节),
        这些数据编码在扇区上的磁性材料中. 扇区之间由一些间隙(gap)分隔开, 这些间隙中不存储数据位. 间隙存储用来标识扇区的格式化位.
        磁盘是由一个或多个叠放在一起的盘片组成的, 它们被封装在一个密封的包装里. 整个装置通常被称为 磁盘驱动器(disk drive),
        通常简称为 磁盘(disk). 有时称 磁盘为旋转磁盘(rotating disk), 以使之区别于基于闪存的固态硬盘(SSD), SSD 是没有移动部分的.
        磁盘制造商通常用术语 柱面(cylinder)来描述多个盘片驱动器的构造, 这里, 柱面是所有盘片表面上到主轴中心的距离相等的磁道的集合.
        例如, 如果一个驱动器有三个盘片和六个面, 每个表面上的磁道和编号都是一致的, 那么柱面 k 就是 6 个磁道 k 的集合.
       2. 磁盘容量:
        一个磁盘上可以记录的最大位数为它的最大容量, 或者简称为 容量. 磁盘容量是由以下技术原因决定的:
        -- 记录密度(recording density)(位/英寸): 磁道一英寸的段中可以放入的位数.
        -- 磁道密度(track density)(道/英寸): 从盘片中心出发半径上一英寸的段内可以有的磁道数.
        -- 面密度(areal density)(位/平方英寸): 记录密度与刺刀密度的乘积.
       3. 磁盘操作:
         磁盘用 读/写头(read/write head) 来读写存储在磁性表面的位, 而读写头连接到一个 传动臂(actuator arm) 一端.
         通过沿着半径轴前后移动这个 传动臂, 驱动器 可以将 读/写头 定位在盘面上的任何磁道上. 这样的机械运动称为 寻道(seek).
         一旦 读/写头 定位到了期望的磁道上, 那么当磁道上的每个位通过它的下面时, 读/写头 可以感知到这个位的值(读该位),
         也可以修改这个位的值(写该位). 有多个盘片的磁盘针对每个盘面都有一个独立的 读/写头. 读/写头 垂直排列, 一致行动.
         在任何时刻, 所有的 读/写头 都位于同一个柱面上.
         在 传动臂 末端的 读/写头 在磁盘表面高度大约 0.1 微米处的一层薄薄的气垫上飞翔, 速度大约为 80 km/h. 这可以比喻成将
         一座摩天大楼(442 米高) 放到, 然后让它在距离地面 2.5cm(1 英寸)的高度上环绕地球飞行, 绕地球一周只需要 8 秒钟.
         在这样小的间隙里, 盘面上一粒微小的灰层都像一块巨石. 如果 读/写头 碰到了这样的一块巨石, 读/写头 会停下来, 撞到
         盘面--所谓的 读/写头 冲撞(head crash). 为此, 磁盘总是密封包装的.
         磁盘以扇区大小的块来 读写数据. 对扇区的访问时间(access time) 有三个主要的部分:
         寻道时间(seek time), 旋转时间(rotational latency) 和传送时间(transfer time).
         寻道时间:
            为了读取某个目标扇区的内容, 传动臂 首先将 读/写头 定位到包含目标扇区的磁道上. 移动传动臂所需的时间称为 寻道时间.
            寻道时间 T(seek) 依赖于 读/写头 以前的位置和传动臂 在盘面上移动的速度. 现代驱动器中平均寻道时间 T(avg seek) 是
            通过对几千次随机扇区的寻道求平均值来测量的, 通常为 3~9ms. 一次寻道最大时间 T(max seek) 可以高达 20ms.
         旋转时间:
            一旦 读/写头 定位了期望的磁道, 驱动器等待目标扇区的第一个位旋转到 读写头下. 这个步骤的性能依赖于当 读写头 到达目标扇区
            时盘面的位置以及磁盘的旋转速度. 在最坏的情况下, 读写头 刚刚错过了目标扇区, 必须等待磁盘转一整圈.
         传送时间:
            当目标扇区的第一个位位于 读写头下时, 驱动器就可以开始读或者写改扇区的内容了. 一个扇区的传送时间依赖于 旋转速度 和 每条磁道
            的扇区数目.
       4. 逻辑磁盘块
          正如我们看到的那样, 现代磁盘构造复杂, 有多个盘面, 这些盘面上有不同的记录区. 为了对操作系统隐藏这样的复杂性, 现代磁盘将它们的
          构造呈现为一个简单的视图, 一个 B 个扇区大小的 逻辑块 的序列, 序号为 0, 1, ..., B-1. 磁盘封装中有一个小的 硬件/固件设备,
          称为 磁盘控制器, 维护着 逻辑块号和实际(物理)磁盘扇区之间的映射关系.
          当操作系统想要执行一个 I/O 操作时, 例如读一个磁盘扇区的数据到主存, 操作系统会发送一个命令到 磁盘控制器, 让它读某个 逻辑块号.
          控制器上的固件执行一个快速表查找, 将一个 逻辑块号 翻译成一个(盘面, 磁道, 扇区)的三元组, 这个 三元组 唯一地标识了对应的
          物理扇区. 控制器上的硬件会解释这个三元组, 将 读写头 移动到适当的柱面, 等待扇区移动到 读写头下, 将 读写头感知到的位放到
          控制器 上的一个小缓冲区中, 然后将它们复制到主存中.
       注: 格式化的磁盘容量
         磁盘控制器必须对磁盘进行格式化, 然后才能在该磁盘上存储数据. 格式化 包括用 标识扇区 的信息填写扇区之间的间隙, 标识出表面有故障的柱面
         并且不使用它们, 以及在每个区中预留出一组柱面作为备用, 如果区中一个或多个柱面在磁盘使用过程中坏掉了, 就可以使用这些备用的柱面.
         因为存在着这些备用的柱面, 所以磁盘制造商所说的格式化容量比最大容量要小.
       5. 连接 I/O 设备
         例如 图形卡、监视器、鼠标、键盘和磁盘这样的 输入/输出(I/O) 设备, 都是通过 I/O 总线, 例如 Intel 的 外围设备互连(Peripheral Component Interconnect, PCI)
         总线连接到 CPU 和主存的. 系统总线和内存总线是与 CPU 相关的, 与它们不同, 诸如 PCI 这样的 I/O 总线设计成与底层 CPU 无关.
         例如, PC 和 Mac 都可以使用 PCI 总线. 一个典型的 I/O 总线结构, 它连接了 CPU、主存和 I/O 设备.
         虽然 I/O 总线比系统总线和内存总线慢, 但是它可以容纳种类繁多的第三方 I/O 设备.
         -- 通用串行总线(Universal Serial Bus, USB) 控制器是一个连接到 USB 总线的设备的中转机构, USB 总线是一个广泛使用的标准,
            连接各种外围 I/O 设备, 包括键盘、鼠标、调制解调器、数码相机、游戏操纵杆、打印机、外部磁盘驱动器和固态硬盘.
            USB 3.0 总线的最大带宽为 625 MB/s, USB 3.1 总线的最大带宽为 1250 MB/s.
         -- 图形卡(或适配器)包含硬件和软件逻辑, 它们负责代表 CPU 在显示器上画像素.
         -- 主机总线设配器 将一个或多个磁盘连接到 I/O 总线, 使用的是一个特别的 主机总线接口 定义的通信协议. 两个最常用的这样的
            磁盘接口是 SCSI(发音: "scuzzy")和 SATA(发音: "sta-uh"). SCSI 磁盘通常比 SATA 驱动器更快但是也更贵. SCSI 主机总线
            适配器(通常称为 SCSI 控制器)可以支持多个磁盘驱动器, 与 SATA 适配器不同, 它只能支持一个驱动器.
         其他的设备, 例如 网络适配器, 可以通过将适配器插入到主板上空的 扩展槽 中, 从而连接到 I/O 总线, 这些插槽提供了到总线的直接
         电路连接.
       6. 访问磁盘
         CPU 使用一种称为 内存映射 I/O(memory-mapped I/O) 的技术来向 I/O 设备发射命令. 在使用内存映射 I/O 的系统中, 地址空间中有一块地址
         是为与 I/O 设备通信保留的. 每个这样的地址称为 一个 I/O 端口(I/O port). 当一个设备连接到总线时, 它与一个或多个端口相关联(或它被
         映射到一个或多个端口).
         eg: 假设磁盘控制器映射到端口 0xa0. 随后, CPU 可能通过执行三个对地址 0xa0 的存储指令, 发起磁盘读:
            第一条指令是 发送一个命令字, 告诉磁盘发起一个读, 同时还发送了其他的参数, 例如当读完成时, 是否中断 CPU .
            第二条指令指明应该读的逻辑快号.
            第三条指令指明应该存储磁盘扇区内容的主存地址.
            在磁盘控制器收到来自 CPU 的读命令之后, 它将逻辑块号翻译成一个扇区地址, 读该扇区的内容, 然后将这些内容直接传送到主存,
            不需要 CPU 的干涉. 设备可以自己执行读或者写总线事务而不需要 CPU 干涉的过程, 称为 直接内存访问(Direct Memory Access, DMA).
            这种数据传送称为 DMA 传送(DMA transfer).
            在 DMA 传送完成, 磁盘扇区的内容被安全地存储在主存中以后, 磁盘控制器通过给 CPU 发送一个中断信号来通知 CPU. 基本思想是
            中断会发信号到 CPU 芯片的一个外部引脚上. 这会导致 CPU 暂停它当前正在做的工作, 跳转到一个操作系统例程. 这个程序会记录下
            I/O 已经完成, 然后将控制返回到 CPU 被中断的地方.
    --------------------
    固态硬盘: Solid State Disk, SSD
        是一种基于闪存的存储技术, 在某些情况下是传统旋转磁盘的极有吸引力的替代产品. SSD 封装插到 I/O 总线上标准硬盘插槽(通常是 USB
        或 SATA)中, 行为就和其他硬盘一样, 处理来自 CPU 的读写逻辑磁盘块的请求. 一个 SSD 封装有一个或多个闪存芯片和闪存翻译层(flash
        translation layer) 组成, 闪存芯片替代传统旋转磁盘中的机械驱动器, 而闪存翻译层是一个硬件/固件设备, 扮演与磁盘控制器相同的角色,
        将对逻辑块的请求翻译成对低层物理设备的访问.
        读 SSD 比写要快. 随机读和写的性能差别是由低层闪存基本属性决定的. 一个闪存有 B 个块的序列组成, 每个块由 P 页组成. 通常, 页的大小
        是 512 字节~4 kb, 块是由 32~128 页组成的, 块的大小为 16KB~512KB. 数据是以页为单位读写的. 只有在一页所属的块整个被檫除之后,
        才能写这一页(通常是指该块中的所有位都被设置为 1). 不过, 一旦一个块被擦除了, 块中每一个页都可以不需要再进行擦除就写一次.
        在大约进行 100,000 次重复写之后, 块就会莫损坏. 一旦一个块磨损坏之后, 就不能再使用了.
        随机写很慢, 有两个原因. 首先, 檫除块需要相对较长的时间, 1ms 级的, 比访问页所需时间要高一个数量级. 其次, 如果写操作试图修改一个包含
        已经有数据(也就是不是全为 1)的页 p, 那么这个块中所有带有用数据的页都必须被复制到一个新(擦除过的)块, 然后才能进行对页 p 的写. 制造商
        已经在闪存翻译层中实现了复杂的逻辑, 试图抵消擦写块的高昂代价, 最小化内部写的次数, 但是随机写的性能不太可能和读一样好.
        比起旋转磁盘, SSD 有很多优点. 它们由半导体存储器构成, 没有移动的部件, 因而随机访问时间比旋转磁盘要快, 能耗更低, 同时也更结实.
        不过, 也有一些缺点. 首先, 因为反复写之后, 闪存块会磨损, 所以 SSD 也容易磨损. 闪存翻译层中的 平均磨损(wear leveling)逻辑视图通过将
        擦除平均分布在所有的块上来最大化每个块的寿命. 实际上, 平均磨损逻辑处理的非常好, 要很多年 SSD 才会莫损坏. 其次, SSD 每字节
        比旋转磁盘贵大约 30 倍, 因此常用的存储容量比旋转磁盘小 100 倍.
    -------------
    局部性:
        一个编写良好的计算机程序常常具有良好的局部性(locality). 也就是, 它们倾向于引用邻近于其他最近引用过的数据项的数据项, 或者最近引用过
        的数据项本身. 这种倾向性, 被称为 局部性原理(principle of locality), 是一个持久的概念, 对硬件和软件系统的设计和性能都有着极大的影响.
        局部性通常有两种不同的形式:
        -- 时间局部性: temporal locality
           在一个具有良好时间局部性的程序中, 被引用过一次的内存位置很可能在不远的将来再被多次引用.
        -- 空间局部性: spatial locality
           在一个具有良好空间局部性的程序中, 如果一个内存位置被引用了一次, 那么程序很可能在不远的将来引用附近的一个内存位置.
        程序员应该理解局部性原理, 因为一般而言, 有良好局部性的程序比局部性差的程序运行的更快. 现代计算机系统的各个层次, 从硬件到操作系统、
        再到应用程序, 它们的设计都利用了局部性. 在硬件层, 局部性原里允许计算机设计者通过引入称为 高速缓存存储器 的小而快速的存储器来保存
        最近被引用的指令和数据项, 从而提高对主存的访问速度. 在操作系统级, 局部性原理允许系统使用主存作为虚拟地址空间最近被引用块的高速缓存.
        类似地, 操作系统用主存来缓存磁盘文件系统中最近被使用的磁盘块. 局部性原理 在应用程序的设计中也扮演着重要的角色. 例如, Web 浏览器将
        最近被引用的文档放在本地磁盘上, 利用的就是时间局部性. 大容量的 Web 服务器将最近被请求的文档放在前端磁盘高速缓存中, 这些缓存能满足
        对这些文档的请求, 而不需要服务器的任何干预.
    --------------------------------------
    缓存命中
       当程序需要第 k+1 层的某个数据对象 d 时, 它首先在当前存储在第 k 层的一个块中查找 d. 如果 d 刚好缓存在第 k 层中, 那么就是我们所说的
       缓存命中(cache hit). 该程序直接从第 k 层读取 d, 根据存储器层次结构的性质, 这要比从第 k+1 层读取 d 更快.
    缓存不命中
       另一方面, 如果第 k 层中没有缓存数据对象 d, 那么就是我们所说的 缓存不命中(cache miss). 当发生缓存不命中时, 第 k 层的缓存
       从第 k+1 层缓存中取出包含 d 的那个块, 如果第 k 层的缓存已经满了, 可能就会覆盖现存的一个块.
       覆盖一个现存的块的过程称为 替换(replacing)或驱逐(evicting) 这个块. 被驱逐的这个块有时也称为 牺牲块(victim block).
       决定改替换哪个块是由缓存的 替换策略(replacement policy)来控制的.
    缓存不命中的种类
        一个空的缓存有时被称为 冷缓存(cold cache), 此类不命中称为 强制性不命中(compulsory miss)或冷不命中(cold miss).
        冷不命中很重要, 因为它们通常是短暂的事件, 不会反复访问存储器使得 缓存暖身(warmed up)之后的稳定状态中出现.
        只要发生了不命中, 第 k 层的缓存就必须执行某个 放置策略(placement policy), 确定把它从第 k+1 层中取出的块放在哪里.
        最灵活的替换策略是允许来自第 k+1 层的任何块放在第 k 层的任何块中. 对于存储器层次结构中高层的缓存(靠近 CPU),
        它们是用硬件来实现的, 而且速度是最优的, 这个策略实现起来通常很昂贵, 因为随机的放置块, 定位起来代价很高.
        因此, 硬件缓存通常使用的是更严的放置策略, 这个策略将第 k+1 层的某个块限制放置在第 k 层块的一个小的子集中(有时只是一个块).
        这种限制性的放置策略会引起一种不命中, 称为 冲突不命中(conflict miss), 在这种情况下, 缓存足够大, 能够保存被引用的数据对象,
        但是因为这些对象会映射到同一个缓存块, 缓存会一直不命中.
        程序通常是按照一系列阶段(如循环)来运行的, 每个阶段访问缓存块的某个相对稳定不变的集合. 例如, 一个嵌套的循环可能会反复地访问
        同一个数组的元素. 这个块地集合称为 这个阶段地工作集(working set). 当工作集的大小超过缓存的大小时, 缓存会经历 容量不命中(capacity miss).
        换句话说就是, 缓存太小了, 不能处理这个工作集.
    缓存管理
        正如我们提到过的, 存储器层次结构的本质是, 每一层存储设备都是较低一层的缓存. 在每一层上, 某种形式的逻辑必须管理缓存.
        这里, 我们的意思是指某个东西要将缓存划分成块, 在不同的层之间传送快, 判定是命中还是不命中, 并处理它们. 管理缓存的逻辑
        可以是硬件、软件, 或是两者的结合.
        例如, 编译器管理寄存器文件, 缓存层次结构的最高层. 它决定当发生不命中时何时发射加载, 以及确定哪个寄存器来存放数据.
        L1、L2 和 L3 层的缓存完全是由内置在缓存中的硬件逻辑来管理的. 在一个有虚拟内存的系统中, DRAM 主存作为存储在磁盘上的
        数据块的缓存, 是由操作系统软件和 CPU 上的地址翻译硬件共同管理的. 对于一个具有像 AFS 这样的分布式文件系统的机器来说,
        本地磁盘作为缓存, 它是由运行在本地机器上的 AFS 客户端进程管理的. 在大多数时候, 缓存都是自动运行的, 不需要程序采取
        特殊的或显示的行动.
        相关术语:
        TLB: 翻译后备缓冲器(Translation Lookaside Buffer)
        MMU: 内存管理系统(Memory Management Unit)
        OS: 操作系统(Operating System)
        AFS: 安德鲁文件系统(Andrew File System)
        NFS: 网络文件系统(Network File System)
    高速缓存存储器
        早期计算机系统的存储器层次结构只有三层: CPU 寄存器、DRAM 主存储器和磁盘存储。
        不过, 由于 CPU 和主存之间逐渐增大的差距, 系统设计者被迫在 CPU 寄存器文件和主存之间插入了一个小的 SRAM 高速缓存存储器,
        称为 L1 高速缓存(一级缓存). L1 高速缓存的访问速度几乎和寄存器一样快, 典型的是大约 4 个时钟周期.
        随着 CPU 和主存之间的性能差距不断增大, 系统设计者在 L1 高速缓存和主存之间又插入了一个更大的高速缓存, 称为 L2 高速缓存,
        可以在大约 10 个时钟周期内访问到它. 有些现代系统还包括有一个更大的高速缓存, 称为 L3 高速缓存, 在存储器层次结构中,
        它位于 L2 高速缓存和主存之间, 可以在大约 50 个周期内存访问到它. 虽然安排上有相当多的变化, 但是通用原则是一样的.
---------------------------------------------------
链接: linking
    将各种代码和数据片段收集并组合成为一个单一文件的过程, 这个文件可被加载(复制)到内存并执行.
    链接可以执行于 编译时(compile time), 也就是在源代码翻译成机器代码时; 也可以在源代码被翻译成机器代码时; 也可以执行于 加载时(load time),
    也就是在程序被加载器(loader)加载到内存并执行时; 甚至执行于 运行时(run time), 也就是由应用程序来执行. 在早期的计算机系统中,
    链接是手动执行的. 在现代系统中, 链接是由叫做 链接器(linker)的程序来自动执行的.
    链接器 在软件开发中扮演着一个关键的角色, 因为它们使得 分离编译(separate compilation) 成为可能. 我们不用将一个大型的应用程序组织为
    一个巨大的源文件, 而是可以把它分解为更小、更好管理的模块, 可以独立地修改和编译这些模块. 当我们改变这些模块中的一个时, 只需简单地
    重新编译它, 并重新链接应用, 而不必重新编译其他文件.
    链接通常是由链接器来默默地处理的, 对于那些在编程入门课堂上构造小程序的学生而言, 链接不是一个重要的议题.
    为什么还要这么麻烦地学习关于链接的知识呢?
    -- 理解链接器将帮助你构造大型程序.
       构造大型程序的程序员经常会遇到由于缺少模块、缺少库或则不兼容的库版本引起的链接器错误. 除非你理解链接器是如何解析引用、
       什么是库以及链接器是如何使用库来解析引用的, 否则这类错误将令你感到迷惑和挫败.
    -- 理解链接器将帮助你避免一些危险的编程错误.
       Linux 链接器解析符号引用时所作的决定可以不动声色地影响你程序的正确性. 在默认情况下, 错误地定义多个全局变量的程序将通过
       链接器, 而不产生任何警告信息. 由此得到的程序会产生令人迷惑的运行时行为, 而且非常难以调试. 我们将向你展示这是如何发生的,
       以及该如何避免它.
    -- 理解链接将帮助你理解语言的作用域规则是如何实现的.
       例如, 全局和局部变量之间的区别是什么? 当你定义一个具有 static 属性的变量或者函数时, 实际到底意味着什么?
    -- 理解链接将帮助你理解其他重要的系统概念.
       链接器产生的可执行目标文件在重要的系统功能中扮演着关键角色, 比如加载和运行程序、虚拟内存、分页、内存映射.
    -- 理解链接将使你能够利用共享库.
       多年以来, 链接都被认为是相当简单和无趣的. 然而, 随着共享库和动态链接在现代操作系统中重要性的日益加强, 链接成为一个
       复杂的过程, 为掌握它的程序员提供了强大的能力. 比如, 许多软件产品在运行时使用共享库来升级压缩包装的(shrink-wrapped)
       二进制程序. 还有, 大多数 Web 服务器都依赖于共享库的动态链接来提供动态内容.
   静态链接
     像 Linux LD 程序这样的静态链接器(static linker)以一组可重定位目标文件和命令行参数作为输入, 生成一个完全链接的、可以加载
     和运行的可执行目标文件作为输出. 输入的可重定位目标文件由各种不同的代码和数据节(section)组成, 每一节都是一个连续的字节序列.
     指令在一节中, 初始化了的全局变量在另一节中, 而未初始化的变量又在另外一节中.
     为了构造可执行文件, 链接器必须完成两个主要任务:
     -- 符号解析(symbol resolution).
        目标文件定义和引用符号, 每个符号对应于一个函数、一个全局变量或一个静态变量(即 C 语言中任何以 static 属性声明的变量).
        符号解析的目的是将每个符号引用正好和一个符号定义关联起来.
     -- 重定位(relocation).
        编译器和汇编器生成从地址 0 开始的代码和数据节. 链接器通过把每个符号定义与一个内存位置关联起来, 从而 重定位 这些节,
        然后修改所有对这些符号的引用, 使得它们指向这个内存位置. 链接器使用汇编器产生的重定位条目(relocation entry)的详细指令,
        不加甄别地执行这样地重定位.
   目标文件
      1. 可重定位目标文件. 包含二进制代码和数据, 其形式可以在编译时与其他可重定位目标文件合并起来, 创建一个可执行目标文件.
      2. 可执行目标文件. 包含二进制代码和数据, 其形式可以被直接复制到内存并执行.
      3. 共享目标文件. 一种特殊类型地可重定位目标文件, 可以在加载或者运行时被动态地加载进内存并链接.
      编译器和汇编器 生成可重定位目标文件(包括共享目标文件). 链接器生成可执行目标文件. 从技术上来说, 一个目标模块(object module)
      就是一个字节序列, 而一个目标文件(object file)就是一个以文件形式存放在磁盘中的目标模块.
      目标文件是按照特定的目标文件格式来组织的, 各个系统的目标文件格式都不相同.
      从贝尔实验室诞生的第一个 Unix 系统使用的是 a.out 格式(知道今天, 可执行文件仍然称为 a.out 文件).
      Windows 使用 可移植可执行(Portable Executable, PE) 格式. Mac-OS-X 使用 Mach-O 格式.
      现代 x86-64 Linux 和 Unix 系统使用 可执行可链接格式(Executable and Linkable Format, ELF).
      ------------------
VM: Virtual Memory 虚拟内存. 现代操作系统提供的一种对主存的抽象概念. 虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件
    的完美交互, 它为每个进程提供了一个大的、一致的和私有的地址空间. 通过一个很清晰的机制, 虚拟内存提供了三个重要能力:
    -- 它将主存看成是一个存储在磁盘上的地址空间的高速缓存, 在主存中只保存活动区域, 并根据需要在磁盘和主存之间来回传送数据,
       通过这种方式, 它高效地使用了主存.
    -- 它为每个进程提供了一致的地址空间, 从而简化了内存管理.
    -- 它保护了每个进程的地址空间不被其他进程破坏.
    虚拟内存 是计算机系统最重要的概念之一. 它成功的一个主要原因就是因为它是沉默地、自动地工作地, 不需要应用程序员地任何干涉.
    既然虚拟内存在幕后工作得如此之好, 为什么程序员还需要理解它呢?
    1. 虚拟内存是核心的
       虚拟内存 遍及计算机系统的所有层面, 在硬件异常、汇编器、链接器、加载器、共享对象、文件和进程的设计中扮演着重要角色.
       理解虚拟内存将帮助你更好地理解系统通常是如何工作的.
    2. 虚拟内存是强大的
       虚拟内存给与应用程序强大的能力, 可以创建和销毁内存片(chunk)、将内存片映射到磁盘文件的某个部分, 以及与其他进程共享内存.
       比如, 你知道可以通过读写内存位置读或者修改一个磁盘文件的内容吗? 或者可以加载一个文件的内容到内存中, 而不需要进行任何显示
       地复制吗? 理解虚拟内存将帮助你利用它地强大功能在应用程序中添加动力.
    3. 虚拟内存是危险的
       每次应用程序引用一个变量、间接引用一个指针, 或者调用一个诸如 malloc 这样的动态分配程序时, 它就会和虚拟内存发生交互.
       如果虚拟内存使用不当, 应用将遇到复杂危险的与内存有关的错误. 例如, 一个带有错误指针的程序可以立即崩溃于 "段错误" 或者
       "保护错误", 它可能在崩溃之前还默默地运行了几个小时, 或者是最令人惊慌地, 运行完成却产生不正确地结果. 理解虚拟内存以及
       诸如 malloc 之类地管理虚拟内存的分配程序, 可以帮助你避免这些错误.
    -------------------------------------------
    物理和虚拟地址
      计算机系统的主存被组织成一个由 M 个连续的字节大小的单元组成的数组. 每字节都有一个唯一的 物理地址(physical address, PA).
      第一个字节地址为 0, 接下来的字节地址为 1, 以此类推. 0~M-1. 给定这种简单的结构, CPU 访问内存的最自然的方式就是使用
      物理地址, 把这种方式称为 物理寻址(physical addressing).
      现代处理器使用的是一种称为 虚拟寻址(virtual addressing)的寻址形式. 使用虚拟寻址, CPU 通过生成一个虚拟地址(virtual address, VA)
      来访问主存, 这个虚拟地址在被送到内存之前先转换成适当的物理地址. 将一个虚拟地址转换成物理地址的任务叫做 地址翻译(address translation).
      CPU 芯片上叫做 内存管理单元(Memory Management Unit, MMU) 的专用硬件, 利用存放在主存中的查询表来动态翻译虚拟地址, 该表的内容
      由操作系统管理.
    地址空间: address space
       一个非负整数地址的有序集合: {0, 1, 2, ...}
       如果地址空间中的整数是连续的, 那么我们说它是一个 线性地址空间(linear address space), 其对应的虚拟地址称为 虚拟地址空间(virtual address space).
       一个地址空间的大小是由表示最大地址所需的位数来描述的. 例如, 一个包含 N = 2^n 个地址的虚拟地址空间就叫做一个 n 位地址空间(32 位或 64 位).
       一个系统还有一个 物理地址空间(physical address space), 对应于系统中物理内存的 M 个字节. {0, 1, ..., M-1}
       地址空间的概念是很重要的, 因为它清楚地区分了数据对象(字节)和它们的属性(地址). 一旦认识到这种区别, 那么我们就可以将其推广, 允许每个数据
       对象有多个独立的地址, 其中每个地址都选自一个不同的地址空间. 这就是 虚拟内存的基本思想. 主存中的每个字节都有一个选自虚拟地址空间的
       虚拟地址和一个选自物理地址空间的物理地址.
    虚拟内存作为缓存的工具
        概念上而言, 虚拟内存被组织为一个由存放在磁盘上的 N 个连续的字节大小的单元组成的数组. 每字节都有一个唯一的虚拟地址, 作为
        到数组的索引. 磁盘上数组的内容被缓存在主存中. 和存储器层次结构中其他缓存一样, 磁盘(较低层)上的数据被分隔成块, 这些块作为
        磁盘和主存(叫高层)之间的传输单元. VM 系统通过将虚拟内存分隔为称为 虚拟页(Virtual Page, VP)的大小固定的块来处理这个问题.
        每个虚拟页的大小为 P = 2^p 字节. 类似地, 物理内存被分割为 物理页(Physical Page, PP), 大小也为 P 字节(物理页也被称为 页帧(page frame)).
        在任意时刻, 虚拟页面的集合都分为三个不相交的子集:
        未分配的: VM 系统还未分配(或者创建)的页. 未分配的块没有任何数据和它们相关联, 因此也就不占用任何磁盘空间.
        缓存的: 当前已缓存在物理内存中的已分配页.
        未缓存的: 未缓存在物理内存中的已分配页.
---------------------------
UDP: Unreliable Datagram Protocol. 不可靠数据报协议.
MIME: Multipurpose Internet Mail Extensions. 多用途的网际邮件扩充协议.
URL: Universal Resource Locator. 通用资源定位符.
     eg: http://www.google.com:80/index.html
     解释: 因特网主机 www.google.com 上一个称为 /index.html 的 HTML 文件, 它是由一个监听端口 80 的 web 服务器管理的.
        端口是可选的, 默认 HTTP 端口 80.
        可以使用 "?" 分隔文件名和参数, 而且每个参数都用 "&" 字符分隔.
HTTP 请求
   一个 HTTP 请求的组成:
      1. 一个 请求行(request line): get/post...
      2. 零到多个请求报头(request header): key-value(header-name: header-data) 形式
      3. 再跟随一个空的文本行来终止报头列表
      一个请求行的形式是: method URI version    -- eg: GET / HTTP/1.1   (/就表示 index.html)
URI: Uniform Resource Identifier. 统一资源标识符
    URI 是相应的 URL 的后缀, 包括文件名和可选的参数.
HTTP 响应
    一个 HTTP 响应的组成:
       1. 一个 响应行(response line)
       2. 零个或多个 响应报头(response header)
       3. 终止报头的空行
       4. 响应主题(response body)
       一个响应行的格式是
       version status-code status-message    -- eg: HTTP/1.0 200 OK
       状态码(status-code) 是一个三位正整数, 指明对请求的处理.
       状态消息(status message) 给出与错误代码等价的英文描述.
问题:
    客户端如何将程序参数传递给服务器?
    服务器如何将这些参数传递给它所创建的子进程?
    服务器如何将子进程生成内容所需的其他信息传递给子进程?
    子进程将它的输出发送到哪里?
    一个称为 CGI(Common Gateway Interface, 通用网关接口)的实际标准的出现解决了这些问题.
--------------
基于 I/O 多路复用的并发编程
    服务器如何响应两个独立的 I/O 事件:
     1) 网络客户端发起连接请求;
     2) 用户在键盘上键入命令行.
     先等待哪个事件呢?
   针对这种困境的一个解决办法就是 I/O 多路复用(I/O multiplexing) 技术.
   基本思路就是 select 函数, 要求内核挂起进程, 只有在一个或多个 I/O 事件发生后, 才将控制返回给应用程序.

互斥锁加锁顺序规则: 给定所有互斥操作的一个全序, 如果每个线程都是以一种顺序获得互斥锁并以相反的顺序释放, 那么这个程序就是无死锁的.

-----------------------------------------------------------------------------------------
编码

在布尔代数中, 遵循和传统代数相同的定律: 交换律, 结合律, 分配律(操作符 * 对 + 的分配),
除此之外, 操作符 + 也可以对 * 进行分配: W + (B × F) = (W + B) × (W + F). (这在传统代数中是不成立的).
解释: 这个式子表示 白猫(W)和 黑色母猫(B * F)的 并集 和等式右边两个集合的 交集 是一样的.
    这两个集合是 白猫 和 黑猫 的 并集(W + B)及 白猫 和 母猫 的 并集(W + F).
  在布尔代数中, 这是一个极其重要的规律.

继电器(六大门电路):
    串联: AND, ×, 与门
        同时为 1 输出 1.
    并联: OR, +, 或门
        至少一个为 1 输出 1.
    非: NOT, 非门
    或非: NOR, (先"或"再"非"). 和 或门 相反.
         当且仅当两输入端都为 0 时输出为 1.
            -- 若原始输出端为高电压(灯泡亮), 两继电器端输入至少一个高电压("或"), 输出端则为低电压("非").
            eg: 一个串联电路有两个开关, 这两个开关初始状态都为闭合(灯泡亮), 分别受一个(非门)继电器影响.
                当且仅当两个继电器都不通电, 灯泡保持亮的状态, 其他任何情形, 灯泡都会灭.
    与非: NAND, (先"与"再"非"). 和 与门 相反.
         当且仅当两输入端都为 1 时输出为 0.
            -- 若原始输出端为高电压, 当两继电器端输入同时为高电压("与"), 输出端为低电压("非").
            eg: 一个电路, 初始状态为俩并联的闭合开关, 分别受一个 非门继电器 影响.
                当且仅当两继电器都通电时, 俩开关会断开, 电路断开.
        另:
          两个 非门 相与, 等价于 或非.   "非与" == "或非".
          两个 非门 相或, 等价于 与非.   "非或" == "与非".
          此即影响重大的 迪摩根定律.
    异或: Exclusive OR gate/XOR. -- 一个 "或门" 和 一个 "与非门" 相与.
        异或门 输出为 1 时, 两输入端有且只有一个为 1.
        A输入  B输入  或门输出  与非门输出  与输出
         0       0        0        1          0
         0       1        1        1          1
         1       0        1        1          1
         1       1        1        0          0
       注: A,B 同时作为 或门/与非门的输入(并联), 二者的输出再通过 与门 输出.










